{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mantel254/Ewe-language-transcription-model/blob/main/understand_fine_tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKnbBv6jQrCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "62b9b3da-6524-4ff8-f273-a2a2f73da0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Ewe.zip\" -d /content/ewe_data\n",
        "!pip install torchaudio\n",
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaRJltbnRm_L"
      },
      "outputs": [],
      "source": [
        "# ✅ 4. Load dataset and prepare paths\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load your CSV\n",
        "df = pd.read_excel('/content/ewe_data/Ewe/selected transcribed audios/selected transcribed audios.xlsx')\n",
        "\n",
        "# Base directory for audio files\n",
        "base_dir = \"/content/ewe_data/Ewe/selected transcribed audios/audios/\"\n",
        "data_path = \"/content/ewe_data/Ewe/selected transcribed audios/audios/\"\n",
        "\n",
        "\n",
        "# Function to clean and construct paths\n",
        "def clean_and_construct_path(path):\n",
        "    # Remove extra \"Ewe/selected transcribed audios/audios\" part\n",
        "    cleaned_path = path.replace('Ewe\\\\selected transcribed audios\\\\audios\\\\', '')  # Use double backslashes for Windows paths\n",
        "    # Normalize slashes and join with base directory\n",
        "    return os.path.join(base_dir, cleaned_path.replace('\\\\', '/'))\n",
        "\n",
        "# Apply the function to the 'AUDIO_PATH' column\n",
        "df['AUDIO_PATH'] = df['AUDIO_PATH'].apply(clean_and_construct_path)\n",
        "\n",
        "# Rename for clarity\n",
        "df = df.rename(columns={'Transcription': 'text', 'AUDIO_PATH': 'audio_path'})\n",
        "\n",
        "# Keep only what we need\n",
        "dataset_df = df[['audio_path', 'text']].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebDfbghHh4jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b1dbdb-d455-4bac-e1e6-1866a389696c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5McJPt0wmAb",
        "outputId": "0cea5429-f3bf-4b28-ed1c-5ce531c5673d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19151, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsZggzBmwrjA"
      },
      "outputs": [],
      "source": [
        "dataset_df = dataset_df[dataset_df['audio_path'].apply(os.path.exists)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR-WL2mXwvfU",
        "outputId": "32137dcd-1567-411c-91bd-9576a40cd4a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19150, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5umc6koLORl"
      },
      "outputs": [],
      "source": [
        "df = dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "CpsMySiHBdT6",
        "outputId": "3356aac7-c11e-41d6-9cc0-8312c488dcf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ewe_data/Ewe/selected transcribed audios/audios/ee_gh_image_0002_u51_1_1687340431752_00004.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.audio_path[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "z9rHJbP9oEnS",
        "outputId": "b2ca187d-41e6-4ad2-f804-435d00346e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ewe_data/Ewe/selected transcribed audios/audios/ee_gh_image_0005_u47_1_1687355379445_00009.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.audio_path[14]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encode_characters_for_ctc(df, text_column='text'):\n",
        "    # 1. Join all text and extract all unique characters (including space)\n",
        "    all_text = ''.join(df[text_column].astype(str).tolist())\n",
        "    unique_chars = sorted(set(all_text))\n",
        "\n",
        "    # 2. Create character-to-index dictionary\n",
        "    char2idx = {char: idx for idx, char in enumerate(unique_chars)}\n",
        "\n",
        "    # 3. Encode each sentence into list of indices\n",
        "    df['encoded_text'] = df[text_column].astype(str).apply(\n",
        "        lambda sentence: [char2idx[char] for char in sentence if char in char2idx]\n",
        "    )\n",
        "\n",
        "    return char2idx, df\n",
        "\n",
        "char2idx, df = label_encode_characters_for_ctc(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "faXrVDv56M6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaurQCuYoEe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e55b77-7a92-4f64-9afd-58502eaef74e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LMVqdFPFex8"
      },
      "outputs": [],
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "\n",
        "class AudioUtil():\n",
        "  # ----------------------------\n",
        "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "   try:\n",
        "      sig, sr = torchaudio.load(audio_file)\n",
        "      # print(f\"sig=={sig}\")\n",
        "      # print(f\"sr=={sr}\")\n",
        "      return (sig, sr)\n",
        "   except Exception as e:  # Catch potential exceptions during audio loading\n",
        "      print(f\"Error loading audio file: {audio_file}. Error: {e}\")\n",
        "      return (None, None)  # Return None values to be handled later\n",
        "  # ----------------------------\n",
        "  # Convert the given audio to the desired number of channels\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def rechannel(aud, new_channel):\n",
        "    sig, sr = aud\n",
        "\n",
        "    if (sig.shape[0] == new_channel):\n",
        "      # print(\"CHANELL=0\")\n",
        "      # Nothing to do\n",
        "      return aud\n",
        "\n",
        "    if (new_channel == 1):\n",
        "      # print(\"HURRAY CHANELL == 1\")\n",
        "      # Convert from stereo to mono by selecting only the first channel\n",
        "      resig = sig[:1, :]\n",
        "    else:\n",
        "      # Convert from mono to stereo by duplicating the first channel\n",
        "      resig = torch.cat([sig, sig])\n",
        "    # print(f\"resig in rechanel=={resig}\")\n",
        "    # print(f\"sr in rechanel=={sr}\")\n",
        "    return (resig, sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Since Resample applies to a single channel, we resample one channel at a time\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def resample(aud, newsr):\n",
        "    # print(\"WE ARE INNN\")\n",
        "    sig, sr = aud\n",
        "    # print(\"Past dividing in  resample\")\n",
        "    if (sr == newsr):\n",
        "      # print(\"IN IF ELSE STATEMENT\")\n",
        "      # Nothing to do\n",
        "      return aud\n",
        "    # print(\"PAST IF ELSE STATEMENT\")\n",
        "    # print(f\"Aud in resample=={aud}\")\n",
        "    num_channels = sig.shape[0]\n",
        "    # print(f\"num chanels == {num_channels}\")\n",
        "    # Resample first channel\n",
        "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
        "    # print(f\"resig output in resample=={resig}\")\n",
        "    if (num_channels > 1):\n",
        "      # Resample the second channel and merge both channels\n",
        "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
        "      resig = torch.cat([resig, retwo])\n",
        "    # print(f\"resig in resample=={resig}\")\n",
        "    # print(f\"newsr in resample=={newsr}\")\n",
        "    return (resig, newsr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def pad_trunc(aud, max_ms):\n",
        "    sig, sr = aud\n",
        "    num_rows, sig_len = sig.shape\n",
        "    max_len = sr//1000 * max_ms\n",
        "    # print(f\"Maximum lenght is {max_len}\")\n",
        "    if (sig_len > max_len):\n",
        "      # Truncate the signal to the given length\n",
        "      sig = sig[:,:max_len]\n",
        "      # print(\"sig > max_len\")\n",
        "      return (sig, sr)\n",
        "    elif (sig_len < max_len):\n",
        "      # print(\"sig < max_len\")\n",
        "      # Length of padding to add at the beginning and end of the signal\n",
        "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
        "      pad_end_len = max_len - sig_len - pad_begin_len\n",
        "\n",
        "      # Pad with 0s\n",
        "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
        "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
        "\n",
        "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
        "      return (sig, sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Shifts the signal to the left or right by some percent. Values at the end\n",
        "  # are 'wrapped around' to the start of the transformed signal.\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def time_shift(aud, shift_limit):\n",
        "    sig,sr = aud\n",
        "    _, sig_len = sig.shape\n",
        "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
        "    return (sig.roll(shift_amt), sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Generate a Spectrogram\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
        "    sig,sr = aud\n",
        "    top_db = 80\n",
        "\n",
        "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
        "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "\n",
        "    # Convert to decibels\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "    return (spec)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
        "  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
        "  # overfitting and to help the model generalise better. The masked sections are\n",
        "  # replaced with the mean value.\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "    _, n_mels, n_steps = spec.shape\n",
        "    mask_value = spec.mean()\n",
        "    aug_spec = spec\n",
        "\n",
        "    freq_mask_param = max_mask_pct * n_mels\n",
        "    for _ in range(n_freq_masks):\n",
        "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    time_mask_param = max_mask_pct * n_steps\n",
        "    for _ in range(n_time_masks):\n",
        "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "    return aug_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfRDaW4ItDs-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEY27g_UhOQS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchaudio\n",
        "\n",
        "# ----------------------------\n",
        "# Sound Dataset\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "  def __init__(self, df, data_path):\n",
        "    self.df = df\n",
        "    self.data_path = str(data_path)\n",
        "    self.duration = 4000\n",
        "    self.sr = 44100\n",
        "    self.channel = 2\n",
        "    self.shift_pct = 0.4\n",
        "\n",
        "  # ----------------------------\n",
        "  # Number of items in dataset\n",
        "  # ----------------------------\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Get i'th item in dataset\n",
        "  # ----------------------------\n",
        "  def __getitem__(self, idx):\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path\n",
        "    # print(\"IN GETITEMM\")\n",
        "    # Handle potential cases where 'audio_path' or 'text' might be dictionaries\n",
        "    # Access data using .iloc to avoid KeyError\n",
        "    try:\n",
        "        audio_file = self.df.iloc[idx]['audio_path']\n",
        "    except KeyError:  # This handles missing index errors\n",
        "        print(f\"KeyError: index {idx} not found, skipping\")\n",
        "        return None\n",
        "    if isinstance(audio_file, dict):  # Check if 'audio_path' is a dictionary\n",
        "        # print(\"AUDIO IS A DICTIONARY\")\n",
        "        audio_file = audio_file.get('path', None)\n",
        "\n",
        "    # print(f\"Audio file path: {audio_file}\")  # Add this line to print the path\n",
        "    # print(\"FUCK YOU\")\n",
        "    # Get the Class ID\n",
        "    try:\n",
        "        class_id = self.df.iloc[idx]['encoded_text'] # Access using .iloc\n",
        "    except KeyError:\n",
        "        print(f\"KeyError: index {idx} not found in 'text', skipping\")\n",
        "        return None\n",
        "    if isinstance(class_id, dict):  # Check if 'text' is a dictionary\n",
        "        # print(f\"Dictionary found in 'text' at index {idx}\")\n",
        "        class_id = class_id.get('label', None)\n",
        "    if audio_file is None or class_id is None:\n",
        "        print(f\"Skipping item at index {idx} due to missing audio_path or text\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "    aud = AudioUtil.open(audio_file)\n",
        "    # print(f\"Aud FUCK YOUU=={aud}\")\n",
        "\n",
        "    if aud[0] is None:  # Check if open function returned None\n",
        "        # print(f\"Skipping file {audio_file} due to loading error\")\n",
        "        return None  # or handle the error in a more appropriate way\n",
        "\n",
        "    # Some sounds have a higher sample rate, or fewer channels compared to the\n",
        "    # majority. So make all sounds have the same number of channels and same\n",
        "    # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
        "    # result in arrays of different lengths, even though the sound duration is\n",
        "    # the same.\n",
        "    reaud = AudioUtil.resample(aud, self.sr)\n",
        "    rechan = AudioUtil.rechannel(reaud, self.channel)\n",
        "\n",
        "    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
        "    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
        "    # ➕ NEW: Convert to MelSpectrogram\n",
        "    spec = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
        "\n",
        "    # ➕ NEW: Apply spectrogram augmentation\n",
        "    aug_spec = AudioUtil.spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1)\n",
        "    # print(f\"Class id is :{class_id}\")\n",
        "    class_id = torch.tensor(class_id, dtype=torch.long)\n",
        "\n",
        "    return aug_spec, class_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3evzvGjp-m"
      },
      "source": [
        "# Prepare Batches of Data with the Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olnQA0JIhNgo",
        "outputId": "1a4e3cca-f52d-4e69-f24f-c2a5600f3539"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19150"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "myds = SoundDS(df, data_path)\n",
        "\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "\n",
        "num_items = len(myds)\n",
        "num_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "JRQJuFxDmMtC",
        "outputId": "34d22c71-0741-40bf-90fd-6847dd16e922",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-60d15a21a3bf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyds\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-60d15a21a3bf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyds\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-ae5477183fbd>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0maud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# print(f\"Aud FUCK YOUU=={aud}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-fff57dd2921a>\u001b[0m in \u001b[0;36mopen\u001b[0;34m(audio_file)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m    \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0;31m# print(f\"sig=={sig}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;31m# print(f\"sr=={sr}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchaudio/_backend/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mbuffer_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     ) -> Tuple[torch.Tensor, int]:\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_src_stream_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_audio_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_load_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36m_load_audio\u001b[0;34m(s, filter, channels_first)\u001b[0m\n\u001b[1;32m     67\u001b[0m ) -> torch.Tensor:\n\u001b[1;32m     68\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_audio_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_desc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_packets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torio/io/_streaming_media_decoder.py\u001b[0m in \u001b[0;36mprocess_all_packets\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_all_packets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;34m\"\"\"Process packets until it reaches EOF.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_be\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_packets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_buffer_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "myds = [item for item in myds if item is not None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWvHBDWljQjf"
      },
      "outputs": [],
      "source": [
        "num_items = len(myds)\n",
        "num_items"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    # print(batch.shape)\n",
        "    batche = next(iter(batch))\n",
        "    # print(batche[0].shape)\n",
        "    # print(f\"BATCH {i}: {batch}\")\n",
        "\n",
        "    # Unpack\n",
        "    inputs, targets = zip(*batch)\n",
        "    # print(len(inputs))\n",
        "    # print(len(targets))\n",
        "\n",
        "    # Pad inputs (e.g., audio features if they're variable-length)\n",
        "    inputs_padded = pad_sequence(inputs, batch_first=True)\n",
        "\n",
        "    # Pad targets\n",
        "    targets_padded = pad_sequence(targets, batch_first=True)\n",
        "\n",
        "    # Target lengths (needed for CTC Loss)\n",
        "    target_lengths = torch.tensor([len(t) for t in targets], dtype=torch.long)\n",
        "\n",
        "    return inputs_padded, targets_padded, target_lengths\n"
      ],
      "metadata": {
        "id": "F0OtMD5pmJXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScMVHgSwi76d"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGpa7XC3e89C",
        "outputId": "c285c84c-ade3-4173-b6d1-685292573cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "958\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E7jN4hwqfPp3",
        "outputId": "670c70ab-a560-492a-b385-a33cc2eabff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "BATCH 0: (tensor([[[[-4.2162e+01, -3.5074e+01, -3.5968e+01,  ..., -2.8135e+01,\n",
            "           -3.4980e+01, -3.4179e+01],\n",
            "          [-3.9227e+01, -2.8411e+01, -2.6334e+01,  ..., -1.8011e+01,\n",
            "           -2.6265e+01, -2.7222e+01],\n",
            "          [-2.7841e+01, -2.5902e+01, -2.5212e+01,  ..., -1.4329e+01,\n",
            "           -2.3909e+01, -2.6205e+01],\n",
            "          ...,\n",
            "          [-4.2162e+01, -4.2162e+01, -4.2162e+01,  ..., -4.2162e+01,\n",
            "           -4.2162e+01, -4.2162e+01],\n",
            "          [-4.2162e+01, -4.2162e+01, -4.2162e+01,  ..., -4.2162e+01,\n",
            "           -4.2162e+01, -4.2162e+01],\n",
            "          [-4.2162e+01, -4.2162e+01, -4.2162e+01,  ..., -4.2162e+01,\n",
            "           -4.2162e+01, -4.2162e+01]],\n",
            "\n",
            "         [[-2.4415e+01, -4.2162e+01, -3.3237e+01,  ..., -3.1188e+01,\n",
            "           -3.6577e+01, -3.4559e+01],\n",
            "          [-2.5719e+01, -2.3506e+01, -2.0385e+01,  ..., -2.3384e+01,\n",
            "           -2.7854e+01, -2.8883e+01],\n",
            "          [-3.2990e+01, -2.2427e+01, -1.9939e+01,  ..., -2.1817e+01,\n",
            "           -2.7518e+01, -2.7038e+01],\n",
            "          ...,\n",
            "          [-4.2162e+01, -4.2162e+01, -4.2162e+01,  ..., -4.2162e+01,\n",
            "           -4.2162e+01, -4.2162e+01],\n",
            "          [-4.2162e+01, -4.2162e+01, -4.2162e+01,  ..., -4.2162e+01,\n",
            "           -4.2162e+01, -4.2162e+01],\n",
            "          [-4.2162e+01, -4.2162e+01, -4.2162e+01,  ..., -4.2162e+01,\n",
            "           -4.2162e+01, -4.2162e+01]]],\n",
            "\n",
            "\n",
            "        [[[-2.4369e+01, -3.0599e+01, -2.4319e+01,  ..., -2.4445e+01,\n",
            "           -2.0583e+01, -1.9551e+01],\n",
            "          [-7.7054e+00, -6.4005e+00, -6.1291e+00,  ..., -1.0458e+01,\n",
            "           -1.0622e+01, -8.9961e+00],\n",
            "          [-4.1096e+00, -2.6958e-02,  1.7692e-01,  ..., -3.1318e+00,\n",
            "           -4.0407e+00, -2.5575e+00],\n",
            "          ...,\n",
            "          [-4.5868e+01, -4.5868e+01, -4.5868e+01,  ..., -4.5868e+01,\n",
            "           -4.5868e+01, -4.5868e+01],\n",
            "          [-4.5868e+01, -4.5868e+01, -4.5868e+01,  ..., -4.5868e+01,\n",
            "           -4.5868e+01, -4.5868e+01],\n",
            "          [-4.5868e+01, -4.5868e+01, -4.5868e+01,  ..., -4.5868e+01,\n",
            "           -4.5868e+01, -4.5868e+01]],\n",
            "\n",
            "         [[-1.2084e+01, -2.3300e+01, -2.4098e+01,  ..., -3.4027e+01,\n",
            "           -4.5868e+01, -2.8831e+01],\n",
            "          [-6.0873e+00, -8.1145e+00, -6.7703e+00,  ..., -7.8813e+00,\n",
            "           -7.3229e+00, -7.5157e+00],\n",
            "          [-4.3237e+00, -1.5614e+00, -3.1313e-01,  ..., -1.0068e+00,\n",
            "           -6.8370e-01, -5.0522e-01],\n",
            "          ...,\n",
            "          [-4.5868e+01, -4.5868e+01, -4.5868e+01,  ..., -4.5868e+01,\n",
            "           -4.5868e+01, -4.5868e+01],\n",
            "          [-4.5868e+01, -4.5868e+01, -4.5868e+01,  ..., -4.5868e+01,\n",
            "           -4.5868e+01, -4.5868e+01],\n",
            "          [-4.5868e+01, -4.5868e+01, -4.5868e+01,  ..., -4.5868e+01,\n",
            "           -4.5868e+01, -4.5868e+01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1990e+01, -1.8230e+01, -2.2808e+01,  ..., -1.6749e+01,\n",
            "           -1.3854e+01, -1.6822e+01],\n",
            "          [-1.3774e+01, -2.0720e+01, -1.8102e+01,  ..., -1.1242e+01,\n",
            "           -8.4743e+00, -1.3741e+01],\n",
            "          [-9.6260e+00, -1.5183e+01, -1.5464e+01,  ..., -7.0189e+00,\n",
            "           -7.9175e+00, -1.4591e+01],\n",
            "          ...,\n",
            "          [-4.0986e+01, -4.0986e+01, -4.0986e+01,  ..., -4.0986e+01,\n",
            "           -4.0986e+01, -4.0986e+01],\n",
            "          [-4.0986e+01, -4.0986e+01, -4.0986e+01,  ..., -4.0986e+01,\n",
            "           -4.0986e+01, -4.0986e+01],\n",
            "          [-4.0986e+01, -4.0986e+01, -4.0986e+01,  ..., -4.0986e+01,\n",
            "           -4.0986e+01, -4.0986e+01]],\n",
            "\n",
            "         [[-2.8781e+01, -1.2618e+01, -1.3189e+01,  ..., -2.0938e+01,\n",
            "           -1.4795e+01, -1.4574e+01],\n",
            "          [-2.9756e+01, -1.2872e+01, -2.1238e+01,  ..., -1.4859e+01,\n",
            "           -9.7756e+00, -1.6330e+01],\n",
            "          [-1.8496e+01, -1.6222e+01, -1.4015e+01,  ..., -9.1971e+00,\n",
            "           -9.4671e+00, -1.4342e+01],\n",
            "          ...,\n",
            "          [-3.2283e+01, -4.0986e+01, -4.0986e+01,  ..., -4.0986e+01,\n",
            "           -4.0986e+01, -4.0986e+01],\n",
            "          [-3.2441e+01, -4.0986e+01, -4.0986e+01,  ..., -4.0986e+01,\n",
            "           -4.0986e+01, -4.0986e+01],\n",
            "          [-3.2454e+01, -4.0986e+01, -4.0986e+01,  ..., -4.0986e+01,\n",
            "           -4.0986e+01, -4.0986e+01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.9278e+01,  1.1139e+01,  1.2533e+01,  ...,  7.3840e+00,\n",
            "            7.8687e+00,  9.3799e+00],\n",
            "          [ 2.1109e+01,  2.2165e+01,  2.2901e+01,  ...,  2.0217e+01,\n",
            "            2.1091e+01,  2.1583e+01],\n",
            "          [ 1.4830e+01,  2.0527e+01,  2.1652e+01,  ...,  2.1040e+01,\n",
            "            2.1563e+01,  2.1279e+01],\n",
            "          ...,\n",
            "          [-3.6799e+01, -4.5285e+01, -4.5285e+01,  ..., -4.5285e+01,\n",
            "           -4.5285e+01, -4.5285e+01],\n",
            "          [-3.7010e+01, -4.5285e+01, -4.5285e+01,  ..., -4.5285e+01,\n",
            "           -4.5285e+01, -4.5285e+01],\n",
            "          [-3.7063e+01, -4.5285e+01, -4.5285e+01,  ..., -4.5285e+01,\n",
            "           -4.5285e+01, -4.5285e+01]],\n",
            "\n",
            "         [[ 1.9278e+01,  1.1139e+01,  1.2533e+01,  ...,  7.3840e+00,\n",
            "            7.8687e+00,  9.3799e+00],\n",
            "          [ 2.1109e+01,  2.2165e+01,  2.2901e+01,  ...,  2.0217e+01,\n",
            "            2.1091e+01,  2.1583e+01],\n",
            "          [ 1.4830e+01,  2.0527e+01,  2.1652e+01,  ...,  2.1040e+01,\n",
            "            2.1563e+01,  2.1279e+01],\n",
            "          ...,\n",
            "          [-3.6799e+01, -4.5285e+01, -4.5285e+01,  ..., -4.5285e+01,\n",
            "           -4.5285e+01, -4.5285e+01],\n",
            "          [-3.7010e+01, -4.5285e+01, -4.5285e+01,  ..., -4.5285e+01,\n",
            "           -4.5285e+01, -4.5285e+01],\n",
            "          [-3.7063e+01, -4.5285e+01, -4.5285e+01,  ..., -4.5285e+01,\n",
            "           -4.5285e+01, -4.5285e+01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1990e+01, -3.8245e+01, -3.5038e+01,  ..., -3.1145e+01,\n",
            "           -3.7919e+01, -2.8821e+01],\n",
            "          [-2.1586e+01, -2.2574e+01, -2.0902e+01,  ..., -1.9884e+01,\n",
            "           -2.2311e+01, -1.9520e+01],\n",
            "          [-2.8755e+01, -2.6518e+01, -2.0334e+01,  ..., -1.8175e+01,\n",
            "           -2.2852e+01, -1.9924e+01],\n",
            "          ...,\n",
            "          [-5.3931e+01, -5.3931e+01, -5.3931e+01,  ..., -5.3931e+01,\n",
            "           -5.3931e+01, -5.3931e+01],\n",
            "          [-5.3931e+01, -5.3931e+01, -5.3931e+01,  ..., -5.3931e+01,\n",
            "           -5.3931e+01, -5.3931e+01],\n",
            "          [-5.3931e+01, -5.3931e+01, -5.3931e+01,  ..., -5.3931e+01,\n",
            "           -5.3931e+01, -5.3931e+01]],\n",
            "\n",
            "         [[-2.1990e+01, -3.8245e+01, -3.5038e+01,  ..., -3.1145e+01,\n",
            "           -3.7919e+01, -2.8821e+01],\n",
            "          [-2.1586e+01, -2.2574e+01, -2.0902e+01,  ..., -1.9884e+01,\n",
            "           -2.2311e+01, -1.9520e+01],\n",
            "          [-2.8755e+01, -2.6518e+01, -2.0334e+01,  ..., -1.8175e+01,\n",
            "           -2.2852e+01, -1.9924e+01],\n",
            "          ...,\n",
            "          [-5.3931e+01, -5.3931e+01, -5.3931e+01,  ..., -5.3931e+01,\n",
            "           -5.3931e+01, -5.3931e+01],\n",
            "          [-5.3931e+01, -5.3931e+01, -5.3931e+01,  ..., -5.3931e+01,\n",
            "           -5.3931e+01, -5.3931e+01],\n",
            "          [-5.3931e+01, -5.3931e+01, -5.3931e+01,  ..., -5.3931e+01,\n",
            "           -5.3931e+01, -5.3931e+01]]],\n",
            "\n",
            "\n",
            "        [[[-2.5503e+01, -7.8795e+00, -2.5458e+00,  ..., -8.4436e+00,\n",
            "           -1.0894e+01, -8.5698e+00],\n",
            "          [-1.1716e+01, -9.2255e+00, -5.0445e+00,  ...,  2.2650e+00,\n",
            "           -3.2463e+00, -7.8600e+00],\n",
            "          [-1.4882e+01, -4.5942e+00, -3.1121e+00,  ...,  5.0829e+00,\n",
            "            1.2214e+00, -4.9256e+00],\n",
            "          ...,\n",
            "          [-4.9404e+01, -4.9404e+01, -4.9404e+01,  ..., -4.9404e+01,\n",
            "           -4.9404e+01, -4.9404e+01],\n",
            "          [-4.9404e+01, -4.9404e+01, -4.9404e+01,  ..., -4.9404e+01,\n",
            "           -4.9404e+01, -4.9404e+01],\n",
            "          [-4.9404e+01, -4.9404e+01, -4.9404e+01,  ..., -4.9404e+01,\n",
            "           -4.9404e+01, -4.9404e+01]],\n",
            "\n",
            "         [[-5.7862e+00, -1.7246e+01, -2.0989e+01,  ..., -1.5710e+01,\n",
            "           -1.5642e+01, -2.0649e+01],\n",
            "          [-1.2044e+01, -1.2454e+01, -8.4864e+00,  ...,  1.3187e+00,\n",
            "           -3.4484e+00, -9.5134e+00],\n",
            "          [-1.6898e+01, -6.4267e+00, -5.5015e+00,  ...,  4.2230e+00,\n",
            "            6.6340e-01, -5.2423e+00],\n",
            "          ...,\n",
            "          [-4.9404e+01, -4.9404e+01, -4.9404e+01,  ..., -4.9404e+01,\n",
            "           -4.9404e+01, -4.9404e+01],\n",
            "          [-4.9404e+01, -4.9404e+01, -4.9404e+01,  ..., -4.9404e+01,\n",
            "           -4.9404e+01, -4.9404e+01],\n",
            "          [-4.9404e+01, -4.9404e+01, -4.9404e+01,  ..., -4.9404e+01,\n",
            "           -4.9404e+01, -4.9404e+01]]]]), tensor([[ 93,  64,  63,  ...,   0,   0,   0],\n",
            "        [ 72,  16, 100,  ...,  66,  58,   8],\n",
            "        [ 72,  20,  49,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [ 29,  64, 104,  ...,   0,   0,   0],\n",
            "        [ 22,  44,  54,  ...,   0,   0,   0],\n",
            "        [ 72,  16,  56,  ...,   0,   0,   0]]), tensor([209, 217, 171, 154, 148, 160, 136, 170, 149, 190, 108, 116, 165, 163,\n",
            "         94, 186]))\n",
            "16\n",
            "BATCH 1: (tensor([[[[-18.7657, -16.0075, -17.3151,  ..., -11.3318, -10.7467, -12.1308],\n",
            "          [-26.6707, -24.7151, -25.1255,  ..., -19.4744, -17.7509, -19.5179],\n",
            "          [-33.9156, -37.6638, -35.3879,  ..., -30.8847, -27.4661, -30.8663],\n",
            "          ...,\n",
            "          [-46.7268, -46.7268, -46.7268,  ..., -46.7268, -46.7268, -46.7268],\n",
            "          [-46.7268, -46.7268, -46.7268,  ..., -46.7268, -46.7268, -46.7268],\n",
            "          [-46.7268, -46.7268, -46.7268,  ..., -46.7268, -46.7268, -46.7268]],\n",
            "\n",
            "         [[-11.2533, -12.3436, -11.8923,  ..., -16.2907, -20.0317, -15.3160],\n",
            "          [-20.0455, -21.1876, -20.5134,  ..., -23.0506, -21.2265, -21.7137],\n",
            "          [-34.5001, -38.6724, -35.4690,  ..., -30.9831, -27.4475, -31.4747],\n",
            "          ...,\n",
            "          [-46.7268, -46.7268, -46.7268,  ..., -46.7268, -46.7268, -46.7268],\n",
            "          [-46.7268, -46.7268, -46.7268,  ..., -46.7268, -46.7268, -46.7268],\n",
            "          [-46.7268, -46.7268, -46.7268,  ..., -46.7268, -46.7268, -46.7268]]],\n",
            "\n",
            "\n",
            "        [[[-28.0566, -36.8681, -38.3341,  ..., -30.9194, -36.5471, -22.0459],\n",
            "          [-28.7020, -29.9493, -37.3300,  ..., -24.2930, -28.8721, -17.0980],\n",
            "          [-14.8060, -16.3343, -18.1800,  ...,  -4.8882,  -8.1559,  -8.6737],\n",
            "          ...,\n",
            "          [-38.3341, -38.3341, -38.3341,  ..., -38.3341, -38.3341, -38.3341],\n",
            "          [-38.3341, -38.3341, -38.3341,  ..., -38.3341, -38.3341, -38.3341],\n",
            "          [-38.3341, -38.3341, -38.3341,  ..., -38.3341, -38.3341, -38.3341]],\n",
            "\n",
            "         [[ -4.7850, -31.5628, -27.5909,  ..., -33.3347, -26.1392, -38.3341],\n",
            "          [ -3.6368, -33.8766, -34.5631,  ..., -25.2989, -33.0443, -26.0202],\n",
            "          [ -1.4645, -16.2575, -17.6740,  ...,  -5.8764,  -9.5594, -12.0266],\n",
            "          ...,\n",
            "          [-38.3341, -38.3341, -38.3341,  ..., -38.3341, -38.3341, -38.3341],\n",
            "          [-38.3341, -38.3341, -38.3341,  ..., -38.3341, -38.3341, -38.3341],\n",
            "          [-38.3341, -38.3341, -38.3341,  ..., -38.3341, -38.3341, -38.3341]]],\n",
            "\n",
            "\n",
            "        [[[-13.6397, -11.9818,   3.9370,  ..., -24.2274, -26.8332, -19.7742],\n",
            "          [-22.2323, -13.4181,   3.0288,  ..., -32.2433, -34.7273, -26.9362],\n",
            "          [-25.9571, -13.3614,  -1.7590,  ..., -44.7328, -38.1495, -34.4716],\n",
            "          ...,\n",
            "          [-44.9978, -44.9978, -44.9978,  ..., -44.9978, -44.9978, -44.9978],\n",
            "          [-44.9978, -44.9978, -44.9978,  ..., -44.9978, -44.9978, -44.9978],\n",
            "          [-44.9978, -44.9978, -44.9978,  ..., -44.9978, -44.9978, -44.9978]],\n",
            "\n",
            "         [[-20.3093, -13.0291,   6.3211,  ..., -12.2363, -11.5028, -12.1877],\n",
            "          [-27.7461, -17.3532,   2.5383,  ..., -21.1452, -20.4376, -20.8011],\n",
            "          [-26.7660, -16.8134,  -4.1603,  ..., -44.9978, -37.7722, -34.1591],\n",
            "          ...,\n",
            "          [-44.9978, -44.9978, -44.9978,  ..., -44.9978, -44.9978, -44.9978],\n",
            "          [-44.9978, -44.9978, -44.9978,  ..., -44.9978, -44.9978, -44.9978],\n",
            "          [-44.9978, -44.9978, -44.9978,  ..., -44.9978, -44.9978, -44.9978]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[  6.6083, -13.4483, -11.9159,  ...,  -8.6345, -11.8108, -15.1799],\n",
            "          [ 10.4408,   4.8880,   4.1953,  ...,   1.5551,   1.9383,   3.7098],\n",
            "          [  5.2284,  16.5213,  15.5846,  ...,  15.7628,  14.3023,  15.1189],\n",
            "          ...,\n",
            "          [-44.3732, -44.3732, -44.3732,  ..., -44.3732, -44.3732, -44.3732],\n",
            "          [-44.3732, -44.3732, -44.3732,  ..., -44.3732, -44.3732, -44.3732],\n",
            "          [-44.3732, -44.3732, -44.3732,  ..., -44.3732, -44.3732, -44.3732]],\n",
            "\n",
            "         [[  6.6083, -13.4483, -11.9159,  ...,  -8.6345, -11.8108, -15.1799],\n",
            "          [ 10.4408,   4.8880,   4.1953,  ...,   1.5551,   1.9383,   3.7098],\n",
            "          [  5.2284,  16.5213,  15.5846,  ...,  15.7628,  14.3023,  15.1189],\n",
            "          ...,\n",
            "          [-44.3732, -44.3732, -44.3732,  ..., -44.3732, -44.3732, -44.3732],\n",
            "          [-44.3732, -44.3732, -44.3732,  ..., -44.3732, -44.3732, -44.3732],\n",
            "          [-44.3732, -44.3732, -44.3732,  ..., -44.3732, -44.3732, -44.3732]]],\n",
            "\n",
            "\n",
            "        [[[-15.5999,  -2.0348,  -0.7153,  ...,  -2.8889,   4.8230,   2.2899],\n",
            "          [ -6.4152,  -1.6388,  -3.5668,  ...,  -1.7810,   2.9402,   3.6202],\n",
            "          [ -1.8276,  -2.6865, -10.8468,  ...,  -1.4551,  -3.1515,   1.7348],\n",
            "          ...,\n",
            "          [-49.2463, -49.2463, -49.2463,  ..., -49.2463, -49.2463, -49.2463],\n",
            "          [-49.2463, -49.2463, -49.2463,  ..., -49.2463, -49.2463, -49.2463],\n",
            "          [-49.2463, -49.2463, -49.2463,  ..., -49.2463, -49.2463, -49.2463]],\n",
            "\n",
            "         [[-11.8897,  -4.3694,  -2.5241,  ...,  -0.0969,   6.5455,   2.9711],\n",
            "          [-20.0142,  -3.7076,  -6.3213,  ...,   1.1749,   4.5783,   4.9452],\n",
            "          [ -7.9697,  -4.3220, -14.0967,  ...,   0.7908,  -1.9543,   3.5617],\n",
            "          ...,\n",
            "          [-49.2463, -49.2463, -49.2463,  ..., -49.2463, -49.2463, -49.2463],\n",
            "          [-49.2463, -49.2463, -49.2463,  ..., -49.2463, -49.2463, -49.2463],\n",
            "          [-49.2463, -49.2463, -49.2463,  ..., -49.2463, -49.2463, -49.2463]]],\n",
            "\n",
            "\n",
            "        [[[-42.2282, -24.0952, -27.9617,  ..., -29.1205, -32.3680, -34.5912],\n",
            "          [-14.2069,  -4.2977,  -2.2875,  ...,  -6.8762,  -7.8491,  -8.7885],\n",
            "          [  3.7310,   3.2318,   3.5718,  ...,  -1.0311,  -0.7578,  -0.3464],\n",
            "          ...,\n",
            "          [-46.5097, -46.5097, -46.5097,  ..., -46.5097, -46.5097, -46.5097],\n",
            "          [-46.5097, -46.5097, -46.5097,  ..., -46.5097, -46.5097, -46.5097],\n",
            "          [-46.5097, -46.5097, -46.5097,  ..., -46.5097, -46.5097, -46.5097]],\n",
            "\n",
            "         [[-20.1207, -19.1519, -21.2425,  ..., -26.0721, -22.6317, -23.8393],\n",
            "          [-13.2302,  -4.5590,  -2.1941,  ...,  -6.6454,  -8.0284,  -8.7232],\n",
            "          [  3.7852,   3.0706,   3.5863,  ...,  -0.7260,  -0.8081,  -0.3404],\n",
            "          ...,\n",
            "          [-46.5097, -46.5097, -46.5097,  ..., -46.5097, -46.5097, -46.5097],\n",
            "          [-46.5097, -46.5097, -46.5097,  ..., -46.5097, -46.5097, -46.5097],\n",
            "          [-46.5097, -46.5097, -46.5097,  ..., -46.5097, -46.5097, -46.5097]]]]), tensor([[ 16,  56,  48,  ...,   0,   0,   0],\n",
            "        [ 72,  20, 100,  ...,   0,   0,   0],\n",
            "        [  0,  54,  59,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [ 72,  19,  64,  ...,   0,   0,   0],\n",
            "        [ 72,  19,  64,  ...,   0,   0,   0],\n",
            "        [ 72,  29,  68,  ...,   0,   0,   0]]), tensor([117, 166, 131, 119, 152, 181, 187, 148, 173, 176, 140, 179, 194, 174,\n",
            "        124, 109]))\n",
            "16\n",
            "BATCH 2: (tensor([[[[-30.9938, -35.8410, -35.3672,  ..., -26.1837, -28.4161, -19.8417],\n",
            "          [-35.1651, -34.3151, -32.1197,  ..., -29.9044, -33.0520, -24.7779],\n",
            "          [-43.9146, -37.5707, -33.7516,  ..., -36.7957, -38.6139, -33.7490],\n",
            "          ...,\n",
            "          [-47.5124, -47.5124, -47.5124,  ..., -47.5124, -47.5124, -47.5124],\n",
            "          [-47.5124, -47.5124, -47.5124,  ..., -47.5124, -47.5124, -47.5124],\n",
            "          [-47.5124, -47.5124, -47.5124,  ..., -47.5124, -47.5124, -47.5124]],\n",
            "\n",
            "         [[-17.7973, -19.5260, -19.5018,  ..., -16.2443, -23.7920, -21.0779],\n",
            "          [-26.2362, -27.5786, -26.8445,  ..., -24.1451, -30.6491, -25.1957],\n",
            "          [-41.6707, -37.8204, -32.5464,  ..., -35.8909, -37.4932, -33.8002],\n",
            "          ...,\n",
            "          [-47.5124, -47.5124, -47.5124,  ..., -47.5124, -47.5124, -47.5124],\n",
            "          [-47.5124, -47.5124, -47.5124,  ..., -47.5124, -47.5124, -47.5124],\n",
            "          [-47.5124, -47.5124, -47.5124,  ..., -47.5124, -47.5124, -47.5124]]],\n",
            "\n",
            "\n",
            "        [[[-32.9612, -44.1972, -37.7433,  ..., -37.8282, -35.3875, -30.5455],\n",
            "          [-32.6000, -30.7646, -28.0717,  ..., -31.9698, -33.6729, -27.7775],\n",
            "          [-36.3543, -30.6586, -26.3381,  ..., -29.6516, -30.7893, -33.2197],\n",
            "          ...,\n",
            "          [-54.3361, -54.3361, -54.3361,  ..., -54.3361, -54.3361, -54.3361],\n",
            "          [-54.3361, -54.3361, -54.3361,  ..., -54.3361, -54.3361, -54.3361],\n",
            "          [-54.3361, -54.3361, -54.3361,  ..., -54.3361, -54.3361, -54.3361]],\n",
            "\n",
            "         [[-32.9612, -44.1972, -37.7433,  ..., -37.8282, -35.3875, -30.5455],\n",
            "          [-32.6000, -30.7646, -28.0717,  ..., -31.9698, -33.6729, -27.7775],\n",
            "          [-36.3543, -30.6586, -26.3381,  ..., -29.6516, -30.7893, -33.2197],\n",
            "          ...,\n",
            "          [-54.3361, -54.3361, -54.3361,  ..., -54.3361, -54.3361, -54.3361],\n",
            "          [-54.3361, -54.3361, -54.3361,  ..., -54.3361, -54.3361, -54.3361],\n",
            "          [-54.3361, -54.3361, -54.3361,  ..., -54.3361, -54.3361, -54.3361]]],\n",
            "\n",
            "\n",
            "        [[[-30.7125,  -9.3810, -16.2650,  ...,  -4.1344,  -2.3025,  -3.9963],\n",
            "          [ -4.6748,  -2.0008,  -5.2341,  ...,   1.6702,   1.0701,  -0.8411],\n",
            "          [  4.1241,  -3.4669,  -4.4893,  ...,   0.8069,   1.7590,   0.6067],\n",
            "          ...,\n",
            "          [-47.1423, -47.9346, -47.9346,  ..., -47.9346, -47.9346, -47.9346],\n",
            "          [-47.1997, -47.9346, -47.9346,  ..., -47.9346, -47.9346, -47.9346],\n",
            "          [-47.1478, -47.9346, -47.9346,  ..., -47.9346, -47.9346, -47.9346]],\n",
            "\n",
            "         [[ -7.0648,  -5.2813, -12.3440,  ..., -14.1418, -16.5359, -11.9516],\n",
            "          [ -2.9937,   1.7412,  -0.1399,  ...,  -2.9952,  -4.1020,  -6.1043],\n",
            "          [  5.8495,   2.5713,  -0.2640,  ...,  -2.5921,  -4.2048,  -6.3430],\n",
            "          ...,\n",
            "          [-47.9346, -47.9346, -47.9346,  ..., -47.9346, -47.9346, -47.9346],\n",
            "          [-47.9346, -47.9346, -47.9346,  ..., -47.9346, -47.9346, -47.9346],\n",
            "          [-47.9346, -47.9346, -47.9346,  ..., -47.9346, -47.9346, -47.9346]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 12.3003,   2.0597,  -2.0967,  ...,   6.7416,   5.2036,   4.2780],\n",
            "          [  7.8051,  11.2716,   4.9113,  ...,   8.7007,   1.2506,   2.1498],\n",
            "          [ -1.0491,  12.6153,   9.3885,  ...,  13.8924,  14.5241,  14.7274],\n",
            "          ...,\n",
            "          [-45.3865, -45.3865, -45.3865,  ..., -45.3865, -45.3865, -45.3865],\n",
            "          [-45.3865, -45.3865, -45.3865,  ..., -45.3865, -45.3865, -45.3865],\n",
            "          [-45.3865, -45.3865, -45.3865,  ..., -45.3865, -45.3865, -45.3865]],\n",
            "\n",
            "         [[ 12.3003,   2.0597,  -2.0967,  ...,   6.7416,   5.2036,   4.2780],\n",
            "          [  7.8051,  11.2716,   4.9113,  ...,   8.7007,   1.2506,   2.1498],\n",
            "          [ -1.0491,  12.6153,   9.3885,  ...,  13.8924,  14.5241,  14.7274],\n",
            "          ...,\n",
            "          [-45.3865, -45.3865, -45.3865,  ..., -45.3865, -45.3865, -45.3865],\n",
            "          [-45.3865, -45.3865, -45.3865,  ..., -45.3865, -45.3865, -45.3865],\n",
            "          [-45.3865, -45.3865, -45.3865,  ..., -45.3865, -45.3865, -45.3865]]],\n",
            "\n",
            "\n",
            "        [[[-11.8578, -13.1645, -14.2240,  ..., -14.0719, -15.0206,  -9.4079],\n",
            "          [ -6.2956, -21.9696, -22.7690,  ..., -22.4533, -23.6061, -16.4491],\n",
            "          [ -4.2055, -28.1732, -25.6248,  ..., -25.6113, -22.7078, -18.8060],\n",
            "          ...,\n",
            "          [-40.9290, -50.1109, -50.1109,  ..., -50.1109, -50.1109, -50.1109],\n",
            "          [-40.9750, -50.1109, -50.1109,  ..., -50.1109, -50.1109, -50.1109],\n",
            "          [-40.9392, -50.1109, -50.1109,  ..., -50.1109, -50.1109, -50.1109]],\n",
            "\n",
            "         [[ -3.6029, -16.4907, -17.2923,  ..., -30.1639, -17.7158, -22.9568],\n",
            "          [ -5.3991, -24.9526, -25.5502,  ..., -32.4810, -25.3779, -20.7115],\n",
            "          [ -4.2495, -28.7661, -25.9735,  ..., -23.8647, -21.0971, -20.0623],\n",
            "          ...,\n",
            "          [-40.6950, -50.1109, -50.1109,  ..., -50.1109, -50.1109, -50.1109],\n",
            "          [-40.7409, -50.1109, -50.1109,  ..., -50.1109, -50.1109, -50.1109],\n",
            "          [-40.7041, -50.1109, -50.1109,  ..., -50.1109, -50.1109, -50.1109]]],\n",
            "\n",
            "\n",
            "        [[[ 13.1259, -24.1491,  -3.2522,  ...,   0.1634,  -4.0115,  -2.0561],\n",
            "          [ 13.2816,   9.6498,  11.3298,  ...,  12.3541,  10.2702,   9.6215],\n",
            "          [  7.0505,  12.7794,  14.1089,  ...,  14.3820,  13.4851,  11.4122],\n",
            "          ...,\n",
            "          [-40.2063, -52.4883, -52.4883,  ..., -52.4883, -52.4883, -52.4883],\n",
            "          [-40.7207, -52.4883, -52.4883,  ..., -52.4883, -52.4883, -52.4883],\n",
            "          [-40.8970, -52.4883, -52.4883,  ..., -52.4883, -52.4883, -52.4883]],\n",
            "\n",
            "         [[ 13.1259, -24.1491,  -3.2522,  ...,   0.1634,  -4.0115,  -2.0561],\n",
            "          [ 13.2816,   9.6498,  11.3298,  ...,  12.3541,  10.2702,   9.6215],\n",
            "          [  7.0505,  12.7794,  14.1089,  ...,  14.3820,  13.4851,  11.4122],\n",
            "          ...,\n",
            "          [-40.2063, -52.4883, -52.4883,  ..., -52.4883, -52.4883, -52.4883],\n",
            "          [-40.7207, -52.4883, -52.4883,  ..., -52.4883, -52.4883, -52.4883],\n",
            "          [-40.8970, -52.4883, -52.4883,  ..., -52.4883, -52.4883, -52.4883]]]]), tensor([[ 72,  16,  56,  ...,   0,   0,   0],\n",
            "        [ 72,   0,  16,  ...,   0,   0,   0],\n",
            "        [ 72,  22,  45,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [ 16,  49, 103,  ...,   0,   0,   0],\n",
            "        [ 72,  16,  56,  ...,   0,   0,   0],\n",
            "        [ 72,  16,  56,  ...,   0,   0,   0]]), tensor([150, 185, 127, 166, 177, 145, 137, 298, 152, 243, 123, 231, 173,  84,\n",
            "        250, 125]))\n",
            "16\n",
            "BATCH 3: (tensor([[[[-10.9484, -22.9139, -22.2351,  ..., -22.4453, -23.5283, -29.1877],\n",
            "          [-10.3057, -24.1093, -18.8734,  ..., -19.2620, -14.8975, -18.3489],\n",
            "          [-12.4085, -25.6572, -19.6254,  ..., -16.4156, -16.4033, -16.4656],\n",
            "          ...,\n",
            "          [-34.3398, -42.9119, -42.9119,  ..., -42.9119, -42.9119, -42.9119],\n",
            "          [-34.8940, -42.9119, -42.9119,  ..., -42.9119, -42.9119, -42.9119],\n",
            "          [-35.1108, -42.9119, -42.9119,  ..., -42.9119, -42.9119, -42.9119]],\n",
            "\n",
            "         [[-10.9484, -22.9139, -22.2351,  ..., -22.4453, -23.5283, -29.1877],\n",
            "          [-10.3057, -24.1093, -18.8734,  ..., -19.2620, -14.8975, -18.3489],\n",
            "          [-12.4085, -25.6572, -19.6254,  ..., -16.4156, -16.4033, -16.4656],\n",
            "          ...,\n",
            "          [-34.3398, -42.9119, -42.9119,  ..., -42.9119, -42.9119, -42.9119],\n",
            "          [-34.8940, -42.9119, -42.9119,  ..., -42.9119, -42.9119, -42.9119],\n",
            "          [-35.1108, -42.9119, -42.9119,  ..., -42.9119, -42.9119, -42.9119]]],\n",
            "\n",
            "\n",
            "        [[[  7.9597,  -7.7108, -11.2570,  ..., -11.6633,  -8.5090,  -0.3771],\n",
            "          [  8.1800,  13.0118,   9.7989,  ...,  -5.1312,  -8.7133,  11.0442],\n",
            "          [ 15.2085,  17.3772,  14.1490,  ...,  -6.6014, -12.3323,  15.6553],\n",
            "          ...,\n",
            "          [-29.2119, -48.3342, -48.3342,  ..., -48.3342, -48.3342, -43.3825],\n",
            "          [-29.2630, -48.3342, -48.3342,  ..., -48.3342, -48.3342, -43.4644],\n",
            "          [-29.2161, -48.3342, -48.3342,  ..., -48.3342, -48.3342, -43.4172]],\n",
            "\n",
            "         [[ 22.8593,  -9.2624,  -6.3111,  ..., -18.4723, -18.1193,  -7.6266],\n",
            "          [ 29.0597,  22.4630,  21.7571,  ..., -13.1023, -15.8617,  -8.3955],\n",
            "          [ 29.4176,  27.6129,  25.8794,  ..., -14.5070, -15.7289,   5.6073],\n",
            "          ...,\n",
            "          [-28.3191, -48.3342, -48.3342,  ..., -48.3342, -48.3342, -43.0729],\n",
            "          [-28.1608, -48.3342, -48.3342,  ..., -48.3342, -48.3342, -43.3422],\n",
            "          [-28.0250, -48.3342, -48.3342,  ..., -48.3342, -48.3342, -43.4211]]],\n",
            "\n",
            "\n",
            "        [[[ 10.8295, -10.4559, -10.7965,  ...,  -5.6268,  -6.9858, -15.9080],\n",
            "          [ 11.2915,   3.1883,   3.9472,  ...,   1.0745,   3.2061,   2.2606],\n",
            "          [  7.4889,  16.1466,  12.7770,  ...,  21.7040,  21.5492,  21.5445],\n",
            "          ...,\n",
            "          [-43.4558, -43.4558, -43.4558,  ..., -43.4558, -43.4558, -43.4558],\n",
            "          [-43.4558, -43.4558, -43.4558,  ..., -43.4558, -43.4558, -43.4558],\n",
            "          [-43.4558, -43.4558, -43.4558,  ..., -43.4558, -43.4558, -43.4558]],\n",
            "\n",
            "         [[ 11.9594,  -9.0325, -11.5929,  ...,  -6.4936,  -8.3020, -15.1901],\n",
            "          [ 12.2929,   4.5383,   4.5113,  ...,  -0.3544,   2.3396,   0.7357],\n",
            "          [ 10.3542,  17.9576,  14.1987,  ...,  20.1755,  20.0200,  19.9387],\n",
            "          ...,\n",
            "          [-43.4558, -43.4558, -43.4558,  ..., -43.4558, -43.4558, -43.4558],\n",
            "          [-43.4558, -43.4558, -43.4558,  ..., -43.4558, -43.4558, -43.4558],\n",
            "          [-43.4558, -43.4558, -43.4558,  ..., -43.4558, -43.4558, -43.4558]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-14.6750,  -5.5077,  -4.1804,  ..., -13.2274, -11.2698,  -8.8376],\n",
            "          [-14.9467,  -8.4537,  -7.3237,  ..., -17.5845, -15.1952, -11.0703],\n",
            "          [-17.7541, -15.6644, -15.5974,  ..., -24.0551, -23.6344, -18.1693],\n",
            "          ...,\n",
            "          [-39.4641, -39.4641, -39.4641,  ..., -39.4641, -39.4641, -39.4641],\n",
            "          [-39.4641, -39.4641, -39.4641,  ..., -39.4641, -39.4641, -39.4641],\n",
            "          [-39.4641, -39.4641, -39.4641,  ..., -39.4641, -39.4641, -39.4641]],\n",
            "\n",
            "         [[-19.3264,  -5.6743,  -4.0920,  ..., -12.4354, -10.4518,  -7.3681],\n",
            "          [-15.0378,  -8.5184,  -6.8330,  ..., -16.6474, -14.1185,  -9.8726],\n",
            "          [-19.4386, -16.1522, -14.5859,  ..., -24.6862, -21.8391, -17.2465],\n",
            "          ...,\n",
            "          [-39.4641, -39.4641, -39.4641,  ..., -39.4641, -39.4641, -39.4641],\n",
            "          [-39.4641, -39.4641, -39.4641,  ..., -39.4641, -39.4641, -39.4641],\n",
            "          [-39.4641, -39.4641, -39.4641,  ..., -39.4641, -39.4641, -39.4641]]],\n",
            "\n",
            "\n",
            "        [[[  8.3474, -13.5671,  -8.9539,  ..., -20.4173, -30.4054,  -8.6366],\n",
            "          [  8.7814, -20.4037, -16.3281,  ..., -18.4520, -33.7209, -11.1581],\n",
            "          [ 10.2152, -17.4647, -15.6219,  ..., -18.9203, -23.2246,  -6.2091],\n",
            "          ...,\n",
            "          [-29.7089, -48.2763, -48.2763,  ..., -48.2763, -48.2763, -48.2763],\n",
            "          [-29.7689, -48.2763, -48.2763,  ..., -48.2763, -48.2763, -48.2763],\n",
            "          [-29.7208, -48.2763, -48.2763,  ..., -48.2763, -48.2763, -48.2763]],\n",
            "\n",
            "         [[  6.4156,  -8.3074,  -4.3750,  ...,  -4.4315,  -6.5724, -13.2966],\n",
            "          [  7.8790, -15.9396, -12.8071,  ..., -12.3475, -15.1401,  -7.3815],\n",
            "          [  9.5431, -13.7092, -11.3808,  ..., -17.2571, -18.1942,  -6.7848],\n",
            "          ...,\n",
            "          [-30.4636, -48.2763, -48.2763,  ..., -48.2763, -48.2763, -48.2763],\n",
            "          [-30.5234, -48.2763, -48.2763,  ..., -48.2763, -48.2763, -48.2763],\n",
            "          [-30.4749, -48.2763, -48.2763,  ..., -48.2763, -48.2763, -48.2763]]],\n",
            "\n",
            "\n",
            "        [[[-15.5020, -14.8797, -19.8587,  ..., -23.1321, -25.1583, -16.8378],\n",
            "          [-16.3909,  -9.4136, -11.7425,  ...,  -7.9005, -14.1009,  -7.8504],\n",
            "          [ -9.2047,   2.3865,  -7.1429,  ...,   1.6036,   1.2296,  -5.8612],\n",
            "          ...,\n",
            "          [-18.7589, -44.0143, -44.0143,  ..., -44.0143, -44.0143, -26.3320],\n",
            "          [-18.0686, -44.0143, -44.0143,  ..., -44.0143, -44.0143, -27.1569],\n",
            "          [-17.7667, -44.0143, -44.0143,  ..., -44.0143, -44.0143, -27.4800]],\n",
            "\n",
            "         [[-15.5020, -14.8797, -19.8587,  ..., -23.1321, -25.1583, -16.8378],\n",
            "          [-16.3909,  -9.4136, -11.7425,  ...,  -7.9005, -14.1009,  -7.8504],\n",
            "          [ -9.2047,   2.3865,  -7.1429,  ...,   1.6036,   1.2296,  -5.8612],\n",
            "          ...,\n",
            "          [-18.7589, -44.0143, -44.0143,  ..., -44.0143, -44.0143, -26.3320],\n",
            "          [-18.0686, -44.0143, -44.0143,  ..., -44.0143, -44.0143, -27.1569],\n",
            "          [-17.7667, -44.0143, -44.0143,  ..., -44.0143, -44.0143, -27.4800]]]]), tensor([[72, 99, 58,  ...,  0,  0,  0],\n",
            "        [39, 48, 65,  ...,  0,  0,  0],\n",
            "        [ 0, 57, 68,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [97, 48, 65,  ...,  0,  0,  0],\n",
            "        [72, 93, 64,  ...,  0,  0,  0],\n",
            "        [72, 29, 68,  ...,  0,  0,  0]]), tensor([211, 105, 146, 147, 161, 192, 261, 130, 117, 173, 153, 140, 137, 191,\n",
            "        184, 230]))\n",
            "16\n",
            "BATCH 4: (tensor([[[[-26.2462, -28.0616, -29.2799,  ..., -24.3274, -27.4662, -27.7729],\n",
            "          [-14.5824, -17.2708, -19.0279,  ..., -14.2958, -17.3081, -15.5273],\n",
            "          [-10.5558, -16.5209, -22.3262,  ..., -13.3556, -22.0289, -14.1446],\n",
            "          ...,\n",
            "          [-38.7278, -38.7278, -38.7278,  ..., -38.7278, -38.7278, -38.7278],\n",
            "          [-38.7278, -38.7278, -38.7278,  ..., -38.7278, -38.7278, -38.7278],\n",
            "          [-38.7278, -38.7278, -38.7278,  ..., -38.7278, -38.7278, -38.7278]],\n",
            "\n",
            "         [[-22.9684, -28.2274, -26.4301,  ..., -23.3755, -23.5684, -27.0226],\n",
            "          [-17.5627, -18.3895, -20.2604,  ..., -17.3679, -20.6543, -17.4748],\n",
            "          [-12.2237, -19.8225, -22.2544,  ..., -17.0590, -25.9693, -15.9756],\n",
            "          ...,\n",
            "          [-38.7278, -38.7278, -38.7278,  ..., -38.7278, -38.7278, -38.7278],\n",
            "          [-38.7278, -38.7278, -38.7278,  ..., -38.7278, -38.7278, -38.7278],\n",
            "          [-38.7278, -38.7278, -38.7278,  ..., -38.7278, -38.7278, -38.7278]]],\n",
            "\n",
            "\n",
            "        [[[ 19.4580,  -8.7238, -10.8985,  ...,  -8.7999,  -0.1384,   0.5240],\n",
            "          [ 23.8776,  16.5370,  16.6190,  ...,  17.5360,  17.0534,  16.8511],\n",
            "          [ 24.2446,  21.4738,  21.3926,  ...,  21.8698,  21.6228,  20.4451],\n",
            "          ...,\n",
            "          [-45.4616, -45.4616, -45.4616,  ..., -45.4616, -45.4616, -45.4616],\n",
            "          [-45.4616, -45.4616, -45.4616,  ..., -45.4616, -45.4616, -45.4616],\n",
            "          [-45.4616, -45.4616, -45.4616,  ..., -45.4616, -45.4616, -45.4616]],\n",
            "\n",
            "         [[ 19.4580,  -8.7238, -10.8985,  ...,  -8.7999,  -0.1384,   0.5240],\n",
            "          [ 23.8776,  16.5370,  16.6190,  ...,  17.5360,  17.0534,  16.8511],\n",
            "          [ 24.2446,  21.4738,  21.3926,  ...,  21.8698,  21.6228,  20.4451],\n",
            "          ...,\n",
            "          [-45.4616, -45.4616, -45.4616,  ..., -45.4616, -45.4616, -45.4616],\n",
            "          [-45.4616, -45.4616, -45.4616,  ..., -45.4616, -45.4616, -45.4616],\n",
            "          [-45.4616, -45.4616, -45.4616,  ..., -45.4616, -45.4616, -45.4616]]],\n",
            "\n",
            "\n",
            "        [[[-22.7393, -35.2402, -42.4768,  ..., -38.6587, -32.2915, -30.0603],\n",
            "          [-22.0431, -20.0420, -28.2425,  ..., -30.0136, -26.6547, -34.1356],\n",
            "          [-23.9358, -14.2364, -30.3755,  ..., -24.1016, -18.9758, -24.8915],\n",
            "          ...,\n",
            "          [-45.2656, -45.2656, -45.2656,  ..., -45.2656, -45.2656, -45.2656],\n",
            "          [-45.2656, -45.2656, -45.2656,  ..., -45.2656, -45.2656, -45.2656],\n",
            "          [-45.2656, -45.2656, -45.2656,  ..., -45.2656, -45.2656, -45.2656]],\n",
            "\n",
            "         [[-22.7393, -35.2402, -42.4768,  ..., -38.6587, -32.2915, -30.0603],\n",
            "          [-22.0431, -20.0420, -28.2425,  ..., -30.0136, -26.6547, -34.1356],\n",
            "          [-23.9358, -14.2364, -30.3755,  ..., -24.1016, -18.9758, -24.8915],\n",
            "          ...,\n",
            "          [-45.2656, -45.2656, -45.2656,  ..., -45.2656, -45.2656, -45.2656],\n",
            "          [-45.2656, -45.2656, -45.2656,  ..., -45.2656, -45.2656, -45.2656],\n",
            "          [-45.2656, -45.2656, -45.2656,  ..., -45.2656, -45.2656, -45.2656]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ -7.4701,  -7.3081,  -9.3266,  ...,   2.1071,   1.6185,   0.1928],\n",
            "          [-24.9939, -24.9939, -24.9939,  ..., -24.9939, -24.9939, -24.9939],\n",
            "          [-43.2892, -30.1232, -29.1686,  ..., -27.5503, -27.8960, -30.9624],\n",
            "          ...,\n",
            "          [-46.9187, -46.9187, -46.9187,  ..., -46.9187, -46.9187, -46.9187],\n",
            "          [-46.9187, -46.9187, -46.9187,  ..., -46.9187, -46.9187, -46.9187],\n",
            "          [-46.9187, -46.9187, -46.9187,  ..., -46.9187, -46.9187, -46.9187]],\n",
            "\n",
            "         [[ -0.1694,  -2.9847,  -1.9763,  ...,  -6.0057,  -7.1104,  -7.1688],\n",
            "          [-24.9939, -24.9939, -24.9939,  ..., -24.9939, -24.9939, -24.9939],\n",
            "          [-25.8562, -28.5454, -32.9886,  ..., -35.2840, -34.4955, -37.4684],\n",
            "          ...,\n",
            "          [-46.9187, -46.9187, -46.9187,  ..., -46.9187, -46.9187, -46.9187],\n",
            "          [-46.9187, -46.9187, -46.9187,  ..., -46.9187, -46.9187, -46.9187],\n",
            "          [-46.9187, -46.9187, -46.9187,  ..., -46.9187, -46.9187, -46.9187]]],\n",
            "\n",
            "\n",
            "        [[[-15.1559, -21.5813, -24.2964,  ..., -29.2317, -23.9791, -16.6510],\n",
            "          [-17.3398,  -8.4640,  -8.2657,  ..., -18.8396, -19.3046, -18.7845],\n",
            "          [ -3.1597,  -2.9834,  -3.4532,  ..., -14.1038, -14.8136, -13.9343],\n",
            "          ...,\n",
            "          [-52.7750, -52.7750, -52.7750,  ..., -52.7750, -52.7750, -52.7750],\n",
            "          [-52.7750, -52.7750, -52.7750,  ..., -52.7750, -52.7750, -52.7750],\n",
            "          [-52.7750, -52.7750, -52.7750,  ..., -52.7750, -52.7750, -52.7750]],\n",
            "\n",
            "         [[-26.0140, -27.8828, -23.1004,  ..., -22.0488, -14.7047, -14.8005],\n",
            "          [-14.6698, -11.0968, -12.6764,  ..., -16.5223, -15.7194, -16.3466],\n",
            "          [ -5.1766,  -5.8211,  -7.0578,  ..., -11.9055, -11.2131,  -9.1082],\n",
            "          ...,\n",
            "          [-52.7750, -52.7750, -52.7750,  ..., -52.7750, -52.7750, -52.7750],\n",
            "          [-52.7750, -52.7750, -52.7750,  ..., -52.7750, -52.7750, -52.7750],\n",
            "          [-52.7750, -52.7750, -52.7750,  ..., -52.7750, -52.7750, -52.7750]]],\n",
            "\n",
            "\n",
            "        [[[ -4.1382,  -3.4998,  -3.5529,  ...,  -3.1289,  -3.0878,  -3.4003],\n",
            "          [-13.1039, -12.2150, -12.5119,  ..., -12.0971, -12.0154, -12.3262],\n",
            "          [-31.3579, -29.8405, -36.9514,  ..., -41.2280, -36.7086, -34.6333],\n",
            "          ...,\n",
            "          [-45.8199, -45.8199, -45.8199,  ..., -45.8199, -45.8199, -45.8199],\n",
            "          [-45.8199, -45.8199, -45.8199,  ..., -45.8199, -45.8199, -45.8199],\n",
            "          [-45.8199, -45.8199, -45.8199,  ..., -45.8199, -45.8199, -45.8199]],\n",
            "\n",
            "         [[ -2.6910,  -3.1898,  -3.1396,  ...,  -3.6398,  -3.6386,  -3.3648],\n",
            "          [-11.6632, -11.8948, -12.1035,  ..., -12.6074, -12.5547, -12.2912],\n",
            "          [-30.9493, -29.3268, -37.0552,  ..., -41.3727, -36.3026, -34.3880],\n",
            "          ...,\n",
            "          [-45.8199, -45.8199, -45.8199,  ..., -45.8199, -45.8199, -45.8199],\n",
            "          [-45.8199, -45.8199, -45.8199,  ..., -45.8199, -45.8199, -45.8199],\n",
            "          [-45.8199, -45.8199, -45.8199,  ..., -45.8199, -45.8199, -45.8199]]]]), tensor([[ 16, 100,  48,  ...,   0,   0,   0],\n",
            "        [ 72,  16,  56,  ...,   0,   0,   0],\n",
            "        [ 72,  16,  56,  ...,   0,   0,   0],\n",
            "        ...,\n",
            "        [ 72,  16,  56,  ...,   0,   0,   0],\n",
            "        [ 72,  33,  64,  ...,   0,   0,   0],\n",
            "        [ 72,  20,  54,  ...,   0,   0,   0]]), tensor([124, 123, 105, 235, 111, 176, 113, 225, 157, 148, 155, 237, 189, 177,\n",
            "        198,  57]))\n"
          ]
        }
      ],
      "source": [
        "dl_iter = iter(train_dl)\n",
        "for i in range(5):\n",
        "    batch = next(dl_iter)\n",
        "    print(f\"BATCH {i}: {batch}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbE4gVOvUpfM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fa70be17-507b-4316-dccd-5e3940802ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "16\n",
            "torch.Size([16, 2, 64, 344])\n"
          ]
        }
      ],
      "source": [
        "batche = next(iter(train_dl))\n",
        "print(batche[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I74nP-Tq6Pnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(char2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCmvDI1x67p4",
        "outputId": "a3cf9e4d-f81a-4783-9af6-8ac690d9317e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "1ltue0vh9_G6",
        "outputId": "0bf09606-fded-47f9-a190-3d383326fa76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          audio_path  \\\n",
              "0  /content/ewe_data/Ewe/selected transcribed aud...   \n",
              "1  /content/ewe_data/Ewe/selected transcribed aud...   \n",
              "2  /content/ewe_data/Ewe/selected transcribed aud...   \n",
              "3  /content/ewe_data/Ewe/selected transcribed aud...   \n",
              "4  /content/ewe_data/Ewe/selected transcribed aud...   \n",
              "\n",
              "                                                text  \\\n",
              "0  Eʋumidzraƒe le mɔ to. Ame aɖewo tɔ ɖe emɔ to. ...   \n",
              "1   ŋutsu et̄ɔwo le mashinidɔwɔƒe le dɔ wɔm, wo d...   \n",
              "2   Ɖevi aɖewo kple nyɔnu aɖe nɔ seƒoƒo nyui aɖew...   \n",
              "3   Yevunyɔnu aɖe kple ɖevi woame eve wole seƒoƒo...   \n",
              "4  Ɖevi adre le teƒe ƒoɖi aɖe  kotokuwo le wogbɔ ...   \n",
              "\n",
              "                                        encoded_text  \n",
              "0  [20, 107, 64, 56, 52, 47, 69, 61, 44, 100, 48,...  \n",
              "1  [72, 93, 64, 63, 62, 64, 0, 48, 63, 111, 103, ...  \n",
              "2  [72, 97, 48, 65, 52, 0, 44, 104, 48, 66, 58, 0...  \n",
              "3  [72, 39, 48, 65, 64, 57, 68, 103, 57, 64, 0, 4...  \n",
              "4  [97, 48, 65, 52, 0, 44, 47, 61, 48, 0, 55, 48,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3024a532-2b10-4b87-9c5f-08b71f81592b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/ewe_data/Ewe/selected transcribed aud...</td>\n",
              "      <td>Eʋumidzraƒe le mɔ to. Ame aɖewo tɔ ɖe emɔ to. ...</td>\n",
              "      <td>[20, 107, 64, 56, 52, 47, 69, 61, 44, 100, 48,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/ewe_data/Ewe/selected transcribed aud...</td>\n",
              "      <td>ŋutsu et̄ɔwo le mashinidɔwɔƒe le dɔ wɔm, wo d...</td>\n",
              "      <td>[72, 93, 64, 63, 62, 64, 0, 48, 63, 111, 103, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/ewe_data/Ewe/selected transcribed aud...</td>\n",
              "      <td>Ɖevi aɖewo kple nyɔnu aɖe nɔ seƒoƒo nyui aɖew...</td>\n",
              "      <td>[72, 97, 48, 65, 52, 0, 44, 104, 48, 66, 58, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/ewe_data/Ewe/selected transcribed aud...</td>\n",
              "      <td>Yevunyɔnu aɖe kple ɖevi woame eve wole seƒoƒo...</td>\n",
              "      <td>[72, 39, 48, 65, 64, 57, 68, 103, 57, 64, 0, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/ewe_data/Ewe/selected transcribed aud...</td>\n",
              "      <td>Ɖevi adre le teƒe ƒoɖi aɖe  kotokuwo le wogbɔ ...</td>\n",
              "      <td>[97, 48, 65, 52, 0, 44, 47, 61, 48, 0, 55, 48,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3024a532-2b10-4b87-9c5f-08b71f81592b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3024a532-2b10-4b87-9c5f-08b71f81592b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3024a532-2b10-4b87-9c5f-08b71f81592b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6215b50-5494-4809-b5e6-9a63084da5ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6215b50-5494-4809-b5e6-9a63084da5ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6215b50-5494-4809-b5e6-9a63084da5ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 19150,\n  \"fields\": [\n    {\n      \"column\": \"audio_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19150,\n        \"samples\": [\n          \"/content/ewe_data/Ewe/selected transcribed audios/audios/ee_gh_image_0666_u17149_1_1679252363367_07669.mp3\",\n          \"/content/ewe_data/Ewe/selected transcribed audios/audios/ee_gh_image_0015_u989_1_1689829252972_16726.mp3\",\n          \"/content/ewe_data/Ewe/selected transcribed audios/audios/ee_gh_image_0407_u53_1_1687700243914_00317.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19150,\n        \"samples\": [\n          \"\\u00a0Yevu woame eve wole a\\u014buti\\u0256i\\u0256iwuwo me, do ga kukuwo ko nakp\\u0254 be wole d\\u0254 a\\u0256e w\\u0254\\u0192e, katapilla gb\\u0254e ma wole, wo anyigbaku\\u0192e d\\u0254w\\u0254\\u0192e a\\u0256ee ma wole eye m\\u0254wo le w\\u0254nawo le edzi yim eye ame \\u0256o m\\u0254\\u0192onu wok\\u0254 le n\\u0254via h\\u00e3 le nyawo me dzro mee alo wok\\u0254 le nyamele alo nyagb\\u0254mele wok\\u0254 le nya g\\u0254mesem n\\u025b. \",\n          \"\\u00a0\\u014autsu eve le d\\u0254 w\\u0254m le gakpo nu. \\u0189eka tro megbe de n\\u0254via eye wodo wo kat\\u00e3 wodo d\\u0254mewu k\\u0254k\\u0254 \\u028blayi \\u0256eka ke \\u0256eka n\\u0254 anyi eye wo kat\\u00e3 wo\\u0256\\u0254 kuku \\u0256eka ke ame yi ke n\\u0254 anyi e\\u0256\\u0254 ga\\u014bkui eye w\\u00f2sa nu bl\\u0254 \\u0256e ek\\u0254me hen\\u0254 \\u014bku l\\u00e9m \\u0256e gakpoa nu veviee.\",\n          \"\\u00a0Amewo le nu\\u0256u\\u0192e. Agbawo le n\\u0254n\\u0254me vovovowo me le wo k\\u0254me. Nu\\u0256u\\u0256u vovovowo le wo dzi. \\u0189ewo nye gbewo kple l\\u0101 t\\u0254t\\u0254ewo. Gaflo kple h\\u025bwo h\\u0101 le wogb\\u0254. Wine glasiwo le kpl\\u0304\\u0254 dzi. Amewo le nu \\u0256um. Ny\\u0254nu \\u0256eka le nu\\u0256u\\u0256u \\u0256e nu.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded_text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0zXbJtZk479"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "\n",
        "class AudioTranscriber(nn.Module):\n",
        "    def __init__(self, vocab_size=125):  # e.g. 30 tokens for characters\n",
        "        super().__init__()\n",
        "        conv_layers = []\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
        "        self.conv1.bias.data.zero_()\n",
        "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
        "\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
        "        self.conv2.bias.data.zero_()\n",
        "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
        "        self.conv3.bias.data.zero_()\n",
        "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
        "\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
        "        self.conv4.bias.data.zero_()\n",
        "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
        "\n",
        "        self.conv = nn.Sequential(*conv_layers)\n",
        "\n",
        "        # Dummy input to infer final feature size\n",
        "        dummy_input = torch.zeros(1, 2, 64, 64)  # [B, C, H, T] — choose realistic H and T\n",
        "        with torch.no_grad():\n",
        "            out = self.conv(dummy_input)\n",
        "            B, C, H, T = out.shape\n",
        "            feature_size = C * H\n",
        "\n",
        "        self.output_fc = nn.Linear(feature_size, vocab_size)\n",
        "    def forward(self, x):\n",
        "          x = self.conv(x)  # [B, C, H, W] = [16, 64, H', T']\n",
        "\n",
        "          # Transpose: [B, C, H, T] → [B, T, C * H]\n",
        "          B, C, H, T = x.size()\n",
        "          x = x.permute(0, 3, 1, 2)  # [B, T, C, H]\n",
        "          x = x.reshape(B, T, -1)    # [B, T, features]\n",
        "\n",
        "          # print(f\"X shape is : {x.shape}\")\n",
        "          x = self.output_fc(x)      # [B, T, vocab_size]\n",
        "          x = x.permute(1, 0, 2)     # [T, B, vocab_size] → required by CTCLoss\n",
        "\n",
        "          return x\n"
      ],
      "metadata": {
        "id": "2Lh7C6ZvKeC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj_CbIw2lK1K"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def training(model, train_dl, num_epochs):\n",
        "    criterion = nn.CTCLoss(blank=0, zero_infinity=True)  # blank=0 is typical for CTC\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=0.001,\n",
        "        steps_per_epoch=int(len(train_dl)),\n",
        "        epochs=num_epochs,\n",
        "        anneal_strategy='linear'\n",
        "    )\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        k=0\n",
        "        for i, batch in enumerate(train_dl):\n",
        "            # Unpack batch\n",
        "            print(f\"KKK ={k}\")\n",
        "            k=k+1\n",
        "            batche = next(iter(train_dl))\n",
        "            # print(batche[0].shape)\n",
        "            # (audio_features, input_lengths, target_texts) = batch\n",
        "            audio_features, target_texts, target_lenghts = batch\n",
        "            # print(f'Audio features:{audio_features.shape}')\n",
        "\n",
        "            # 🎯 Calculate input_lengths after convolution\n",
        "            with torch.no_grad():\n",
        "                # Pass a sample through the convolutional layers\n",
        "                sample_output = model.conv(audio_features[0].unsqueeze(0).to(device))\n",
        "                # print(f\"sample  shape is : {sample_output.shape}\")\n",
        "                # Get the time dimeoutputnsion after convolution\n",
        "                output_time_dim = sample_output.shape[3]\n",
        "\n",
        "            input_lengths = torch.full(size=(audio_features.size(0),), fill_value=output_time_dim, dtype=torch.long)\n",
        "            # print(f\"lenght of input is : {input_lengths.shape}\")\n",
        "            # print(input_lengths)\n",
        "\n",
        "\n",
        "            # for i, text in enumerate(target_texts):\n",
        "            #   print(f\"Original Text {i}: {text}\")\n",
        "            #   tensor = text_to_tensor(text, word_to_index, word_vectors, device=device)\n",
        "            #   print(f\"Converted Tensor {i}: {tensor}\")\n",
        "\n",
        "\n",
        "\n",
        "            # print(f\"TARGET TEXTS=={target_texts}\")\n",
        "            # target_texts = torch.stack([\n",
        "            # text_to_tensor(text, word_to_index, word_vectors, device=device)\n",
        "            # for text in target_texts\n",
        "              # ])\n",
        "            # target_texts =df['encoded_text']\n",
        "            # print(f\"Target textis :{target_texts}\")\n",
        "            # Convert list of lists to list of tensors\n",
        "            # target_texts = [torch.tensor(t, dtype=torch.long) for t in target_texts]\n",
        "            # targeti_texts = torch.stack(target_texts)\n",
        "            # print(f\"target text ==  {target_texts}\")\n",
        "            # print(f\"LENGTH OF TARGET TEXT IS: {targeti_texts.shape}\")\n",
        "\n",
        "            # Target lengths (before padding)\n",
        "            target_lengths = torch.tensor([len(t) for t in target_texts], dtype=torch.long)\n",
        "\n",
        "            # Pad targets to create a tensor of shape (B, S)\n",
        "            # padded_targets = pad_sequence(target_texts, batch_first=True, padding_value=0)\n",
        "            padded_targets = pad_sequence(target_texts, batch_first=True)\n",
        "            # print(f\"Padded_targets is : {padded_targets.shape}\")\n",
        "\n",
        "            # Send to device\n",
        "            audio_features = audio_features.to(device)\n",
        "            padded_targets = padded_targets.to(device)\n",
        "            input_lengths = input_lengths.to(device)\n",
        "            target_lengths = target_lengths.to(device)\n",
        "\n",
        "            # Normalize audio features\n",
        "            mean, std = audio_features.mean(), audio_features.std()\n",
        "            audio_features = (audio_features - mean) / std\n",
        "            # print(f\"AUDIO FEATURES=={audio_features}\")\n",
        "            optimizer.zero_grad()\n",
        "            # audio_features = audio_features.permute(0, 2, 1)\n",
        "            # print(f\"AUDIO FEATURES=={audio_features.shape}\")\n",
        "\n",
        "            # Forward pass: model should return (B, T, C)\n",
        "            outputs = model(audio_features)  # shape: (B, T, C)\n",
        "            # print(f\"Output B== {outputs.shape}\")\n",
        "            # print(outputs)\n",
        "\n",
        "            batch_size = outputs.size(0)\n",
        "            num_classes = outputs.size(1)\n",
        "            seq_len = 44100  # or any fixed T that works for your use case\n",
        "\n",
        "            # outputs = outputs.unsqueeze(1).expand(batch_size, seq_len, num_classes)  # (batch_size, seq_len, num_classes)\n",
        "            # outputs = outputs.permute(1, 0, 2)  # (seq_len, batch_size, num_classes)\n",
        "            outputs = outputs.log_softmax(dim=2)\n",
        "\n",
        "\n",
        "            # outputs = outputs.log_softmax(dim =1)  # log-probabilities over classes\n",
        "            # print(\"AFTER SOFTMAX\")\n",
        "            # print(f\"Output == {outputs.shape}\")\n",
        "\n",
        "            # CTC expects shape (T, B, C)\n",
        "            # outputs = outputs.permute(1, 0, 2)\n",
        "\n",
        "            # Flatten targets as required by nn.CTCLoss\n",
        "            # print(f\"padded targets == {padded_targets.shape}\")\n",
        "            targets_flattened = padded_targets.view(-1)\n",
        "            # print(\"Targets flattened:\", targets_flattened.unique())\n",
        "            # print(\"HEEEEEY\")\n",
        "            # for i in range(len(target_lengths)):\n",
        "            #   print(f\"Input len: {input_lengths[i]}, Target len: {target_lengths[i]}\")\n",
        "\n",
        "\n",
        "            # targets_flattened = torch.cat(target_texts)  # Only real values\n",
        "\n",
        "\n",
        "            # print(f\"OUTPUTS == {outputs.shape}\")\n",
        "            # print(f\"Target flattened == {targets_flattened}\")\n",
        "            # print(f\"Target flattened shape == {targets_flattened.shape}\")\n",
        "            # print(f\"input lengths == {input_lengths}\")\n",
        "            # print(f\"input lengths shape == {input_lengths.shape}\")\n",
        "            # print(f\"target lengths == {target_lengths.shape}\")\n",
        "\n",
        "            # Compute loss\n",
        "            # print(\"BEFORE LOSS\")\n",
        "            # print(\"Logits stats:\", outputs.mean().item(), outputs.std().item())\n",
        "\n",
        "            loss = criterion(outputs, targets_flattened, input_lengths, target_lengths)\n",
        "            # print(\"AFTER LOSS\")\n",
        "            # with torch.no_grad():\n",
        "            #   out_before = model(audio_features).clone()\n",
        "            # optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # for name, param in model.named_parameters():\n",
        "            #    if param.requires_grad and param.grad is not None:\n",
        "            #      print(f\"{name}: grad mean = {param.grad.abs().mean():.6f}\")\n",
        "\n",
        "            optimizer.step()\n",
        "            # with torch.no_grad():\n",
        "            #  out_after = model(audio_features)\n",
        "\n",
        "            # print(\"Change in output:\", (out_before - out_after).abs().mean())\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            # for name, param in model.named_parameters():\n",
        "            #  print(name, \"requires_grad =\", param.requires_grad)\n",
        "\n",
        "\n",
        "        avg_loss = running_loss / len(train_dl)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "\n",
        "myModel = AudioTranscriber()\n",
        "\n",
        "num_epochs=1   # Just for demo, adjust this higher.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "training(myModel, train_dl, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p54v_gVtyRT9",
        "outputId": "fac067f1-bfff-4292-d1aa-539fc6b1bcd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KKK =0\n",
            "KKK =1\n",
            "KKK =2\n",
            "KKK =3\n",
            "KKK =4\n",
            "KKK =5\n",
            "KKK =6\n",
            "KKK =7\n",
            "KKK =8\n",
            "KKK =9\n",
            "KKK =10\n",
            "KKK =11\n",
            "KKK =12\n",
            "KKK =13\n",
            "KKK =14\n",
            "KKK =15\n",
            "KKK =16\n",
            "KKK =17\n",
            "KKK =18\n",
            "KKK =19\n",
            "KKK =20\n",
            "KKK =21\n",
            "KKK =22\n",
            "KKK =23\n",
            "KKK =24\n",
            "KKK =25\n",
            "KKK =26\n",
            "KKK =27\n",
            "KKK =28\n",
            "KKK =29\n",
            "KKK =30\n",
            "KKK =31\n",
            "KKK =32\n",
            "KKK =33\n",
            "KKK =34\n",
            "KKK =35\n",
            "KKK =36\n",
            "KKK =37\n",
            "KKK =38\n",
            "KKK =39\n",
            "KKK =40\n",
            "KKK =41\n",
            "KKK =42\n",
            "KKK =43\n",
            "KKK =44\n",
            "KKK =45\n",
            "KKK =46\n",
            "KKK =47\n",
            "KKK =48\n",
            "KKK =49\n",
            "KKK =50\n",
            "KKK =51\n",
            "KKK =52\n",
            "KKK =53\n",
            "KKK =54\n",
            "KKK =55\n",
            "KKK =56\n",
            "KKK =57\n",
            "KKK =58\n",
            "KKK =59\n",
            "KKK =60\n",
            "KKK =61\n",
            "KKK =62\n",
            "KKK =63\n",
            "KKK =64\n",
            "KKK =65\n",
            "KKK =66\n",
            "KKK =67\n",
            "KKK =68\n",
            "KKK =69\n",
            "KKK =70\n",
            "KKK =71\n",
            "KKK =72\n",
            "KKK =73\n",
            "KKK =74\n",
            "KKK =75\n",
            "KKK =76\n",
            "KKK =77\n",
            "KKK =78\n",
            "KKK =79\n",
            "KKK =80\n",
            "KKK =81\n",
            "KKK =82\n",
            "KKK =83\n",
            "KKK =84\n",
            "KKK =85\n",
            "KKK =86\n",
            "KKK =87\n",
            "KKK =88\n",
            "KKK =89\n",
            "KKK =90\n",
            "KKK =91\n",
            "KKK =92\n",
            "KKK =93\n",
            "KKK =94\n",
            "KKK =95\n",
            "KKK =96\n",
            "KKK =97\n",
            "KKK =98\n",
            "KKK =99\n",
            "KKK =100\n",
            "KKK =101\n",
            "KKK =102\n",
            "KKK =103\n",
            "KKK =104\n",
            "KKK =105\n",
            "KKK =106\n",
            "KKK =107\n",
            "KKK =108\n",
            "KKK =109\n",
            "KKK =110\n",
            "KKK =111\n",
            "KKK =112\n",
            "KKK =113\n",
            "KKK =114\n",
            "KKK =115\n",
            "KKK =116\n",
            "KKK =117\n",
            "KKK =118\n",
            "KKK =119\n",
            "KKK =120\n",
            "KKK =121\n",
            "KKK =122\n",
            "KKK =123\n",
            "KKK =124\n",
            "KKK =125\n",
            "KKK =126\n",
            "KKK =127\n",
            "KKK =128\n",
            "KKK =129\n",
            "KKK =130\n",
            "KKK =131\n",
            "KKK =132\n",
            "KKK =133\n",
            "KKK =134\n",
            "KKK =135\n",
            "KKK =136\n",
            "KKK =137\n",
            "KKK =138\n",
            "KKK =139\n",
            "KKK =140\n",
            "KKK =141\n",
            "KKK =142\n",
            "KKK =143\n",
            "KKK =144\n",
            "KKK =145\n",
            "KKK =146\n",
            "KKK =147\n",
            "KKK =148\n",
            "KKK =149\n",
            "KKK =150\n",
            "KKK =151\n",
            "KKK =152\n",
            "KKK =153\n",
            "KKK =154\n",
            "KKK =155\n",
            "KKK =156\n",
            "KKK =157\n",
            "KKK =158\n",
            "KKK =159\n",
            "KKK =160\n",
            "KKK =161\n",
            "KKK =162\n",
            "KKK =163\n",
            "KKK =164\n",
            "KKK =165\n",
            "KKK =166\n",
            "KKK =167\n",
            "KKK =168\n",
            "KKK =169\n",
            "KKK =170\n",
            "KKK =171\n",
            "KKK =172\n",
            "KKK =173\n",
            "KKK =174\n",
            "KKK =175\n",
            "KKK =176\n",
            "KKK =177\n",
            "KKK =178\n",
            "KKK =179\n",
            "KKK =180\n",
            "KKK =181\n",
            "KKK =182\n",
            "KKK =183\n",
            "KKK =184\n",
            "KKK =185\n",
            "KKK =186\n",
            "KKK =187\n",
            "KKK =188\n",
            "KKK =189\n",
            "KKK =190\n",
            "KKK =191\n",
            "KKK =192\n",
            "KKK =193\n",
            "KKK =194\n",
            "KKK =195\n",
            "KKK =196\n",
            "KKK =197\n",
            "KKK =198\n",
            "KKK =199\n",
            "KKK =200\n",
            "KKK =201\n",
            "KKK =202\n",
            "KKK =203\n",
            "KKK =204\n",
            "KKK =205\n",
            "KKK =206\n",
            "KKK =207\n",
            "KKK =208\n",
            "KKK =209\n",
            "KKK =210\n",
            "KKK =211\n",
            "KKK =212\n",
            "KKK =213\n",
            "KKK =214\n",
            "KKK =215\n",
            "KKK =216\n",
            "KKK =217\n",
            "KKK =218\n",
            "KKK =219\n",
            "KKK =220\n",
            "KKK =221\n",
            "KKK =222\n",
            "KKK =223\n",
            "KKK =224\n",
            "KKK =225\n",
            "KKK =226\n",
            "KKK =227\n",
            "KKK =228\n",
            "KKK =229\n",
            "KKK =230\n",
            "KKK =231\n",
            "KKK =232\n",
            "KKK =233\n",
            "KKK =234\n",
            "KKK =235\n",
            "KKK =236\n",
            "KKK =237\n",
            "KKK =238\n",
            "KKK =239\n",
            "KKK =240\n",
            "KKK =241\n",
            "KKK =242\n",
            "KKK =243\n",
            "KKK =244\n",
            "KKK =245\n",
            "KKK =246\n",
            "KKK =247\n",
            "KKK =248\n",
            "KKK =249\n",
            "KKK =250\n",
            "KKK =251\n",
            "KKK =252\n",
            "KKK =253\n",
            "KKK =254\n",
            "KKK =255\n",
            "KKK =256\n",
            "KKK =257\n",
            "KKK =258\n",
            "KKK =259\n",
            "KKK =260\n",
            "KKK =261\n",
            "KKK =262\n",
            "KKK =263\n",
            "KKK =264\n",
            "KKK =265\n",
            "KKK =266\n",
            "KKK =267\n",
            "KKK =268\n",
            "KKK =269\n",
            "KKK =270\n",
            "KKK =271\n",
            "KKK =272\n",
            "KKK =273\n",
            "KKK =274\n",
            "KKK =275\n",
            "KKK =276\n",
            "KKK =277\n",
            "KKK =278\n",
            "KKK =279\n",
            "KKK =280\n",
            "KKK =281\n",
            "KKK =282\n",
            "KKK =283\n",
            "KKK =284\n",
            "KKK =285\n",
            "KKK =286\n",
            "KKK =287\n",
            "KKK =288\n",
            "KKK =289\n",
            "KKK =290\n",
            "KKK =291\n",
            "KKK =292\n",
            "KKK =293\n",
            "KKK =294\n",
            "KKK =295\n",
            "KKK =296\n",
            "KKK =297\n",
            "KKK =298\n",
            "KKK =299\n",
            "KKK =300\n",
            "KKK =301\n",
            "KKK =302\n",
            "KKK =303\n",
            "KKK =304\n",
            "KKK =305\n",
            "KKK =306\n",
            "KKK =307\n",
            "KKK =308\n",
            "KKK =309\n",
            "KKK =310\n",
            "KKK =311\n",
            "KKK =312\n",
            "KKK =313\n",
            "KKK =314\n",
            "KKK =315\n",
            "KKK =316\n",
            "KKK =317\n",
            "KKK =318\n",
            "KKK =319\n",
            "KKK =320\n",
            "KKK =321\n",
            "KKK =322\n",
            "KKK =323\n",
            "KKK =324\n",
            "KKK =325\n",
            "KKK =326\n",
            "KKK =327\n",
            "KKK =328\n",
            "KKK =329\n",
            "KKK =330\n",
            "KKK =331\n",
            "KKK =332\n",
            "KKK =333\n",
            "KKK =334\n",
            "KKK =335\n",
            "KKK =336\n",
            "KKK =337\n",
            "KKK =338\n",
            "KKK =339\n",
            "KKK =340\n",
            "KKK =341\n",
            "KKK =342\n",
            "KKK =343\n",
            "KKK =344\n",
            "KKK =345\n",
            "KKK =346\n",
            "KKK =347\n",
            "KKK =348\n",
            "KKK =349\n",
            "KKK =350\n",
            "KKK =351\n",
            "KKK =352\n",
            "KKK =353\n",
            "KKK =354\n",
            "KKK =355\n",
            "KKK =356\n",
            "KKK =357\n",
            "KKK =358\n",
            "KKK =359\n",
            "KKK =360\n",
            "KKK =361\n",
            "KKK =362\n",
            "KKK =363\n",
            "KKK =364\n",
            "KKK =365\n",
            "KKK =366\n",
            "KKK =367\n",
            "KKK =368\n",
            "KKK =369\n",
            "KKK =370\n",
            "KKK =371\n",
            "KKK =372\n",
            "KKK =373\n",
            "KKK =374\n",
            "KKK =375\n",
            "KKK =376\n",
            "KKK =377\n",
            "KKK =378\n",
            "KKK =379\n",
            "KKK =380\n",
            "KKK =381\n",
            "KKK =382\n",
            "KKK =383\n",
            "KKK =384\n",
            "KKK =385\n",
            "KKK =386\n",
            "KKK =387\n",
            "KKK =388\n",
            "KKK =389\n",
            "KKK =390\n",
            "KKK =391\n",
            "KKK =392\n",
            "KKK =393\n",
            "KKK =394\n",
            "KKK =395\n",
            "KKK =396\n",
            "KKK =397\n",
            "KKK =398\n",
            "KKK =399\n",
            "KKK =400\n",
            "KKK =401\n",
            "KKK =402\n",
            "KKK =403\n",
            "KKK =404\n",
            "KKK =405\n",
            "KKK =406\n",
            "KKK =407\n",
            "KKK =408\n",
            "KKK =409\n",
            "KKK =410\n",
            "KKK =411\n",
            "KKK =412\n",
            "KKK =413\n",
            "KKK =414\n",
            "KKK =415\n",
            "KKK =416\n",
            "KKK =417\n",
            "KKK =418\n",
            "KKK =419\n",
            "KKK =420\n",
            "KKK =421\n",
            "KKK =422\n",
            "KKK =423\n",
            "KKK =424\n",
            "KKK =425\n",
            "KKK =426\n",
            "KKK =427\n",
            "KKK =428\n",
            "KKK =429\n",
            "KKK =430\n",
            "KKK =431\n",
            "KKK =432\n",
            "KKK =433\n",
            "KKK =434\n",
            "KKK =435\n",
            "KKK =436\n",
            "KKK =437\n",
            "KKK =438\n",
            "KKK =439\n",
            "KKK =440\n",
            "KKK =441\n",
            "KKK =442\n",
            "KKK =443\n",
            "KKK =444\n",
            "KKK =445\n",
            "KKK =446\n",
            "KKK =447\n",
            "KKK =448\n",
            "KKK =449\n",
            "KKK =450\n",
            "KKK =451\n",
            "KKK =452\n",
            "KKK =453\n",
            "KKK =454\n",
            "KKK =455\n",
            "KKK =456\n",
            "KKK =457\n",
            "KKK =458\n",
            "KKK =459\n",
            "KKK =460\n",
            "KKK =461\n",
            "KKK =462\n",
            "KKK =463\n",
            "KKK =464\n",
            "KKK =465\n",
            "KKK =466\n",
            "KKK =467\n",
            "KKK =468\n",
            "KKK =469\n",
            "KKK =470\n",
            "KKK =471\n",
            "KKK =472\n",
            "KKK =473\n",
            "KKK =474\n",
            "KKK =475\n",
            "KKK =476\n",
            "KKK =477\n",
            "KKK =478\n",
            "KKK =479\n",
            "KKK =480\n",
            "KKK =481\n",
            "KKK =482\n",
            "KKK =483\n",
            "KKK =484\n",
            "KKK =485\n",
            "KKK =486\n",
            "KKK =487\n",
            "KKK =488\n",
            "KKK =489\n",
            "KKK =490\n",
            "KKK =491\n",
            "KKK =492\n",
            "KKK =493\n",
            "KKK =494\n",
            "KKK =495\n",
            "KKK =496\n",
            "KKK =497\n",
            "KKK =498\n",
            "KKK =499\n",
            "KKK =500\n",
            "KKK =501\n",
            "KKK =502\n",
            "KKK =503\n",
            "KKK =504\n",
            "KKK =505\n",
            "KKK =506\n",
            "KKK =507\n",
            "KKK =508\n",
            "KKK =509\n",
            "KKK =510\n",
            "KKK =511\n",
            "KKK =512\n",
            "KKK =513\n",
            "KKK =514\n",
            "KKK =515\n",
            "KKK =516\n",
            "KKK =517\n",
            "KKK =518\n",
            "KKK =519\n",
            "KKK =520\n",
            "KKK =521\n",
            "KKK =522\n",
            "KKK =523\n",
            "KKK =524\n",
            "KKK =525\n",
            "KKK =526\n",
            "KKK =527\n",
            "KKK =528\n",
            "KKK =529\n",
            "KKK =530\n",
            "KKK =531\n",
            "KKK =532\n",
            "KKK =533\n",
            "KKK =534\n",
            "KKK =535\n",
            "KKK =536\n",
            "KKK =537\n",
            "KKK =538\n",
            "KKK =539\n",
            "KKK =540\n",
            "KKK =541\n",
            "KKK =542\n",
            "KKK =543\n",
            "KKK =544\n",
            "KKK =545\n",
            "KKK =546\n",
            "KKK =547\n",
            "KKK =548\n",
            "KKK =549\n",
            "KKK =550\n",
            "KKK =551\n",
            "KKK =552\n",
            "KKK =553\n",
            "KKK =554\n",
            "KKK =555\n",
            "KKK =556\n",
            "KKK =557\n",
            "KKK =558\n",
            "KKK =559\n",
            "KKK =560\n",
            "KKK =561\n",
            "KKK =562\n",
            "KKK =563\n",
            "KKK =564\n",
            "KKK =565\n",
            "KKK =566\n",
            "KKK =567\n",
            "KKK =568\n",
            "KKK =569\n",
            "KKK =570\n",
            "KKK =571\n",
            "KKK =572\n",
            "KKK =573\n",
            "KKK =574\n",
            "KKK =575\n",
            "KKK =576\n",
            "KKK =577\n",
            "KKK =578\n",
            "KKK =579\n",
            "KKK =580\n",
            "KKK =581\n",
            "KKK =582\n",
            "KKK =583\n",
            "KKK =584\n",
            "KKK =585\n",
            "KKK =586\n",
            "KKK =587\n",
            "KKK =588\n",
            "KKK =589\n",
            "KKK =590\n",
            "KKK =591\n",
            "KKK =592\n",
            "KKK =593\n",
            "KKK =594\n",
            "KKK =595\n",
            "KKK =596\n",
            "KKK =597\n",
            "KKK =598\n",
            "KKK =599\n",
            "KKK =600\n",
            "KKK =601\n",
            "KKK =602\n",
            "KKK =603\n",
            "KKK =604\n",
            "KKK =605\n",
            "KKK =606\n",
            "KKK =607\n",
            "KKK =608\n",
            "KKK =609\n",
            "KKK =610\n",
            "KKK =611\n",
            "KKK =612\n",
            "KKK =613\n",
            "KKK =614\n",
            "KKK =615\n",
            "KKK =616\n",
            "KKK =617\n",
            "KKK =618\n",
            "KKK =619\n",
            "KKK =620\n",
            "KKK =621\n",
            "KKK =622\n",
            "KKK =623\n",
            "KKK =624\n",
            "KKK =625\n",
            "KKK =626\n",
            "KKK =627\n",
            "KKK =628\n",
            "KKK =629\n",
            "KKK =630\n",
            "KKK =631\n",
            "KKK =632\n",
            "KKK =633\n",
            "KKK =634\n",
            "KKK =635\n",
            "KKK =636\n",
            "KKK =637\n",
            "KKK =638\n",
            "KKK =639\n",
            "KKK =640\n",
            "KKK =641\n",
            "KKK =642\n",
            "KKK =643\n",
            "KKK =644\n",
            "KKK =645\n",
            "KKK =646\n",
            "KKK =647\n",
            "KKK =648\n",
            "KKK =649\n",
            "KKK =650\n",
            "KKK =651\n",
            "KKK =652\n",
            "KKK =653\n",
            "KKK =654\n",
            "KKK =655\n",
            "KKK =656\n",
            "KKK =657\n",
            "KKK =658\n",
            "KKK =659\n",
            "KKK =660\n",
            "KKK =661\n",
            "KKK =662\n",
            "KKK =663\n",
            "KKK =664\n",
            "KKK =665\n",
            "KKK =666\n",
            "KKK =667\n",
            "KKK =668\n",
            "KKK =669\n",
            "KKK =670\n",
            "KKK =671\n",
            "KKK =672\n",
            "KKK =673\n",
            "KKK =674\n",
            "KKK =675\n",
            "KKK =676\n",
            "KKK =677\n",
            "KKK =678\n",
            "KKK =679\n",
            "KKK =680\n",
            "KKK =681\n",
            "KKK =682\n",
            "KKK =683\n",
            "KKK =684\n",
            "KKK =685\n",
            "KKK =686\n",
            "KKK =687\n",
            "KKK =688\n",
            "KKK =689\n",
            "KKK =690\n",
            "KKK =691\n",
            "KKK =692\n",
            "KKK =693\n",
            "KKK =694\n",
            "KKK =695\n",
            "KKK =696\n",
            "KKK =697\n",
            "KKK =698\n",
            "KKK =699\n",
            "KKK =700\n",
            "KKK =701\n",
            "KKK =702\n",
            "KKK =703\n",
            "KKK =704\n",
            "KKK =705\n",
            "KKK =706\n",
            "KKK =707\n",
            "KKK =708\n",
            "KKK =709\n",
            "KKK =710\n",
            "KKK =711\n",
            "KKK =712\n",
            "KKK =713\n",
            "KKK =714\n",
            "KKK =715\n",
            "KKK =716\n",
            "KKK =717\n",
            "KKK =718\n",
            "KKK =719\n",
            "KKK =720\n",
            "KKK =721\n",
            "KKK =722\n",
            "KKK =723\n",
            "KKK =724\n",
            "KKK =725\n",
            "KKK =726\n",
            "KKK =727\n",
            "KKK =728\n",
            "KKK =729\n",
            "KKK =730\n",
            "KKK =731\n",
            "KKK =732\n",
            "KKK =733\n",
            "KKK =734\n",
            "KKK =735\n",
            "KKK =736\n",
            "KKK =737\n",
            "KKK =738\n",
            "KKK =739\n",
            "KKK =740\n",
            "KKK =741\n",
            "KKK =742\n",
            "KKK =743\n",
            "KKK =744\n",
            "KKK =745\n",
            "KKK =746\n",
            "KKK =747\n",
            "KKK =748\n",
            "KKK =749\n",
            "KKK =750\n",
            "KKK =751\n",
            "KKK =752\n",
            "KKK =753\n",
            "KKK =754\n",
            "KKK =755\n",
            "KKK =756\n",
            "KKK =757\n",
            "KKK =758\n",
            "KKK =759\n",
            "KKK =760\n",
            "KKK =761\n",
            "KKK =762\n",
            "KKK =763\n",
            "KKK =764\n",
            "KKK =765\n",
            "KKK =766\n",
            "KKK =767\n",
            "KKK =768\n",
            "KKK =769\n",
            "KKK =770\n",
            "KKK =771\n",
            "KKK =772\n",
            "KKK =773\n",
            "KKK =774\n",
            "KKK =775\n",
            "KKK =776\n",
            "KKK =777\n",
            "KKK =778\n",
            "KKK =779\n",
            "KKK =780\n",
            "KKK =781\n",
            "KKK =782\n",
            "KKK =783\n",
            "KKK =784\n",
            "KKK =785\n",
            "KKK =786\n",
            "KKK =787\n",
            "KKK =788\n",
            "KKK =789\n",
            "KKK =790\n",
            "KKK =791\n",
            "KKK =792\n",
            "KKK =793\n",
            "KKK =794\n",
            "KKK =795\n",
            "KKK =796\n",
            "KKK =797\n",
            "KKK =798\n",
            "KKK =799\n",
            "KKK =800\n",
            "KKK =801\n",
            "KKK =802\n",
            "KKK =803\n",
            "KKK =804\n",
            "KKK =805\n",
            "KKK =806\n",
            "KKK =807\n",
            "KKK =808\n",
            "KKK =809\n",
            "KKK =810\n",
            "KKK =811\n",
            "KKK =812\n",
            "KKK =813\n",
            "KKK =814\n",
            "KKK =815\n",
            "KKK =816\n",
            "KKK =817\n",
            "KKK =818\n",
            "KKK =819\n",
            "KKK =820\n",
            "KKK =821\n",
            "KKK =822\n",
            "KKK =823\n",
            "KKK =824\n",
            "KKK =825\n",
            "KKK =826\n",
            "KKK =827\n",
            "KKK =828\n",
            "KKK =829\n",
            "KKK =830\n",
            "KKK =831\n",
            "KKK =832\n",
            "KKK =833\n",
            "KKK =834\n",
            "KKK =835\n",
            "KKK =836\n",
            "KKK =837\n",
            "KKK =838\n",
            "KKK =839\n",
            "KKK =840\n",
            "KKK =841\n",
            "KKK =842\n",
            "KKK =843\n",
            "KKK =844\n",
            "KKK =845\n",
            "KKK =846\n",
            "KKK =847\n",
            "KKK =848\n",
            "KKK =849\n",
            "KKK =850\n",
            "KKK =851\n",
            "KKK =852\n",
            "KKK =853\n",
            "KKK =854\n",
            "KKK =855\n",
            "KKK =856\n",
            "KKK =857\n",
            "KKK =858\n",
            "KKK =859\n",
            "KKK =860\n",
            "KKK =861\n",
            "KKK =862\n",
            "KKK =863\n",
            "KKK =864\n",
            "KKK =865\n",
            "KKK =866\n",
            "KKK =867\n",
            "KKK =868\n",
            "KKK =869\n",
            "KKK =870\n",
            "KKK =871\n",
            "KKK =872\n",
            "KKK =873\n",
            "KKK =874\n",
            "KKK =875\n",
            "KKK =876\n",
            "KKK =877\n",
            "KKK =878\n",
            "KKK =879\n",
            "KKK =880\n",
            "KKK =881\n",
            "KKK =882\n",
            "KKK =883\n",
            "KKK =884\n",
            "KKK =885\n",
            "KKK =886\n",
            "KKK =887\n",
            "KKK =888\n",
            "KKK =889\n",
            "KKK =890\n",
            "KKK =891\n",
            "KKK =892\n",
            "KKK =893\n",
            "KKK =894\n",
            "KKK =895\n",
            "KKK =896\n",
            "KKK =897\n",
            "KKK =898\n",
            "KKK =899\n",
            "KKK =900\n",
            "KKK =901\n",
            "KKK =902\n",
            "KKK =903\n",
            "KKK =904\n",
            "KKK =905\n",
            "KKK =906\n",
            "KKK =907\n",
            "KKK =908\n",
            "KKK =909\n",
            "KKK =910\n",
            "KKK =911\n",
            "KKK =912\n",
            "KKK =913\n",
            "KKK =914\n",
            "KKK =915\n",
            "KKK =916\n",
            "KKK =917\n",
            "KKK =918\n",
            "KKK =919\n",
            "KKK =920\n",
            "KKK =921\n",
            "KKK =922\n",
            "KKK =923\n",
            "KKK =924\n",
            "KKK =925\n",
            "KKK =926\n",
            "KKK =927\n",
            "KKK =928\n",
            "KKK =929\n",
            "KKK =930\n",
            "KKK =931\n",
            "KKK =932\n",
            "KKK =933\n",
            "KKK =934\n",
            "KKK =935\n",
            "KKK =936\n",
            "KKK =937\n",
            "KKK =938\n",
            "KKK =939\n",
            "KKK =940\n",
            "KKK =941\n",
            "KKK =942\n",
            "KKK =943\n",
            "KKK =944\n",
            "KKK =945\n",
            "KKK =946\n",
            "KKK =947\n",
            "KKK =948\n",
            "KKK =949\n",
            "KKK =950\n",
            "KKK =951\n",
            "KKK =952\n",
            "KKK =953\n",
            "KKK =954\n",
            "KKK =955\n",
            "KKK =956\n",
            "KKK =957\n",
            "Epoch 1/1 - Loss: 1.6615\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssYjovqtlWiy"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3GiR4WSj1Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99837f58-232e-4dfc-b2a5-e0dc0ec659ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.0)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from jiwer import cer # Import Character Error Rate calculation\n",
        "\n",
        "# You need the inverse mapping from index back to character\n",
        "# Create this mapping based on your existing char2idx\n",
        "idx2char = {v: k for k, v in char2idx.items()}\n",
        "# Make sure to handle the blank token index if it's part of your output vocabulary\n",
        "# Assuming blank is index 0 based on nn.CTCLoss(blank=0)\n",
        "idx2char[0] = \"\" # Map blank token to an empty string\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Greedy Decoding function\n",
        "# Converts model output logits to a predicted text sequence\n",
        "# ----------------------------\n",
        "def greedy_decode(output_tensor, idx2char):\n",
        "    \"\"\"\n",
        "    Performs greedy decoding on the model output.\n",
        "\n",
        "    Args:\n",
        "        output_tensor (torch.Tensor): Model output logits, shape (T, B, C) or (B, T, C).\n",
        "                                       Assumes shape (T, B, C) based on your model's forward pass.\n",
        "        idx2char (dict): Dictionary mapping index to character.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predicted strings, one for each item in the batch.\n",
        "    \"\"\"\n",
        "    # output_tensor shape: (T, B, C) -> (T, B, vocab_size)\n",
        "    # Get the index with the highest probability for each time step and each batch item\n",
        "    # shape (T, B)\n",
        "    # print(f\"Shape before argmax: {output_tensor.shape}\")\n",
        "    predictions = torch.argmax(output_tensor, dim=2)\n",
        "    # print(f\"Shape after argmax: {predictions.shape}\")\n",
        "\n",
        "    decoded_texts = []\n",
        "    # Iterate through each item in the batch\n",
        "    for i in range(predictions.shape[1]): # Iterate over batch size (dim 1)\n",
        "        # Get the prediction sequence for the current batch item\n",
        "        prediction_seq = predictions[:, i].tolist() # shape (T,)\n",
        "\n",
        "        decoded_chars = []\n",
        "        # Process the sequence to remove blanks and consecutive duplicates\n",
        "        # Ensure to handle the first token\n",
        "        if prediction_seq:\n",
        "            # Add the first character if it's not the blank token (index 0)\n",
        "            if prediction_seq[0] != 0:\n",
        "                decoded_chars.append(idx2char.get(prediction_seq[0], '')) # Use .get for safety\n",
        "\n",
        "            # Iterate from the second token\n",
        "            for j in range(1, len(prediction_seq)):\n",
        "                # Add the current token if it's not the blank AND it's different from the previous token\n",
        "                # Assuming blank token index is 0\n",
        "                if prediction_seq[j] != 0 and prediction_seq[j] != prediction_seq[j-1]:\n",
        "                     decoded_chars.append(idx2char.get(prediction_seq[j], '')) # Use .get for safety\n",
        "\n",
        "        decoded_texts.append(\"\".join(decoded_chars))\n",
        "\n",
        "    return decoded_texts\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Inference and Evaluation\n",
        "# ----------------------------\n",
        "def inference_and_evaluate(model, val_dl, idx2char):\n",
        "    device = next(model.parameters()).device # Get the device the model is on\n",
        "\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "\n",
        "    all_ground_truth_texts = []\n",
        "    all_predicted_texts = []\n",
        "\n",
        "    # Disable gradient updates\n",
        "    with torch.no_grad():\n",
        "        for data in val_dl:\n",
        "            audio_features, target_texts_encoded, target_lenghts = data\n",
        "            inputs = audio_features\n",
        "\n",
        "            # Move data to the same device as the model\n",
        "            inputs = inputs.to(device)\n",
        "            # We don't need target_texts_encoded or target_lenghts on device for decoding,\n",
        "            # but we do need the original target_texts for evaluation.\n",
        "\n",
        "            # Normalize the inputs\n",
        "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
        "            # FIX: Use inputs_s for standard deviation\n",
        "            inputs = (inputs - inputs_m) / inputs_s\n",
        "\n",
        "            # Forward pass: model output shape (T, B, C)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Perform greedy decoding on the model outputs\n",
        "            # outputs have shape (T, B, C) as required by greedy_decode\n",
        "            predicted_texts = greedy_decode(outputs, idx2char)\n",
        "\n",
        "            # Convert the encoded target texts back to strings for comparison\n",
        "            # target_texts_encoded is a padded tensor (B, S_max)\n",
        "            # We need the original sequences before padding to reconstruct the text\n",
        "            # The original 'target_texts' list from the batch before padding is needed here.\n",
        "            # Since the custom_collate_fn returns 'target_texts_encoded' (padded tensor)\n",
        "            # we need to reconstruct the original strings from the padded tensor and lengths.\n",
        "            ground_truth_texts = []\n",
        "            for i in range(target_texts_encoded.shape[0]): # Iterate over batch size\n",
        "                 # Get the actual length for this item\n",
        "                 length = target_lenghts[i]\n",
        "                 # Get the encoded sequence up to the actual length\n",
        "                 encoded_seq = target_texts_encoded[i, :length].tolist()\n",
        "                 # Convert indices back to characters and join\n",
        "                 # Ensure to handle blank token (index 0) if it's in your ground truth\n",
        "                 # Typically, blank is only in model output, not ground truth.\n",
        "                 # Assuming ground truth does not contain blank (index 0)\n",
        "                 ground_truth_chars = [idx2char.get(idx, '') for idx in encoded_seq if idx != 0]\n",
        "                 ground_truth_texts.append(\"\".join(ground_truth_chars))\n",
        "\n",
        "\n",
        "            # Store ground truth and predicted texts for overall metric calculation\n",
        "            all_ground_truth_texts.extend(ground_truth_texts)\n",
        "            all_predicted_texts.extend(predicted_texts)\n",
        "\n",
        "    # Calculate overall CER for the entire validation set\n",
        "    overall_cer = cer(all_ground_truth_texts, all_predicted_texts)\n",
        "\n",
        "    print(f\"Overall Character Error Rate (CER): {overall_cer:.4f}\")\n",
        "\n",
        "# Run inference and evaluation on trained model with the validation set\n",
        "# Ensure idx2char is created based on your char2idx\n",
        "idx2char = {v: k for k, v in char2idx.items()}\n",
        "idx2char[0] = \"\" # Assuming 0 is the blank index\n",
        "\n",
        "inference_and_evaluate(myModel, val_dl, idx2char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB9u32PUXEum",
        "outputId": "69d928a0-e3b0-48fb-c11e-ea5306ab13a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Character Error Rate (CER): 0.9944\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1egh3CPuC3h8ZQxLhsQGFTNrdRMv0M--m",
      "authorship_tag": "ABX9TyMgz4TUy40uaDI9J5Tk9lUX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}